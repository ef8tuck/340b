-- Databricks notebook source
CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_account_mnc_list (
  CUST_ACCT_ID STRING COMMENT 'CUST_ACCT_ID',
  MNC_CODE STRING COMMENT 'MNC_CODE',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_ACCOUNT_MNC_LIST' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_activestatusupdate (
  CUST_ACCT_ID STRING COMMENT 'CUST_ACCT_ID',
  CUST_ACCT_NAME STRING COMMENT 'CUST_ACCT_NAME',
  ACCT_CLASS STRING COMMENT 'ACCT_CLASS',
  STATUS STRING COMMENT 'STATUS',
  ACTIVE_STATUS_UPDATE STRING COMMENT 'ACTIVE_STATUS_UPDATE',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_ACTIVESTATUSUPDATE' 
TBLPROPERTIES (
 'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.T_CHAINS (
  ID STRING COMMENT 'ID',
 CHAIN STRING COMMENT 'CHAIN',
 IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_CHAINS' 
TBLPROPERTIES (
 'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_contractpharmacy_exceptions (
  ID STRING COMMENT 'ID',
  RETAIL_CHAIN STRING COMMENT 'RETAIL_CHAIN',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_CONTRACTPHARMACY_EXCEPTIONS' 
TBLPROPERTIES (
 'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_gpo_managers (
  GPO_NAME STRING COMMENT 'GPO_NAME',
  SENIOR_ACCOUNT_MANAGER STRING COMMENT 'SENIOR_ACCOUNT_MANAGER',
  ACCOUNT_MANAGER_SUPPORT STRING COMMENT 'ACCOUNT_MANAGER_SUPPORT',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_GPO_MANAGERS' 
TBLPROPERTIES (
 'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_luq_account (
  ID STRING COMMENT 'ID',
  ACCOUNT STRING COMMENT 'ACCOUNT',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_LUQ_ACCOUNT' 
TBLPROPERTIES (
 'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

 CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_lutl_entity (
  ID STRING COMMENT 'ID',
  ENTITY_TYPE STRING COMMENT 'ENTITY_TYPE',
  ENTITY_NAME STRING COMMENT 'ENTITY_NAME',
  EXPANSION_ENTITY STRING COMMENT 'EXPANSION_ENTITY',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_LUTL_ENTITY' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_lutl_non_ordering_accounts (
  ID STRING COMMENT 'ID',
  CUST_ACCT_ID STRING COMMENT 'CUST_ACCT_ID',
  CUST_ACCT_NAME STRING COMMENT 'CUST_ACCT_NAME',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_LUTL_NON_ORDERING_ACCOUNTS'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_lutl_phs_leads (
  ID STRING COMMENT 'ID',
  LEAD STRING COMMENT 'LEAD',
  LEAD_NAME STRING COMMENT 'LEAD_NAME',
  Apexus STRING COMMENT 'Apexus',
  PVP_Flag STRING COMMENT 'PVP_Flag',
  PHS STRING COMMENT 'PHS',
  WAC STRING COMMENT 'WAC',
  Expansion STRING COMMENT 'Expansion',
  DMEM_Org STRING COMMENT 'DMEM_Org',
  DMEM_Id STRING COMMENT 'DMEM_Id',
  DMEM_Seq STRING COMMENT 'DMEM_Id',
  DMEM_Prio STRING COMMENT 'DMEM_Prio',
  DMEM_Pref STRING COMMENT 'DMEM_Pref',
  AGP STRING COMMENT 'AGP',
  LEAD_Unformatted STRING,
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING
  COMMENT 'Rescued Data',
  ADF_RUN_ID STRING
  COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING
  COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp
  COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING
  COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING
  COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING
  COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME))
  COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME))
  COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_LUTL_PHS_LEADS'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

 CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_lutl_pvp_coding (
  ID STRING COMMENT 'ID',
  CODING STRING COMMENT 'CODING',
  PVP_CODING STRING COMMENT 'PVP_CODING',
  NATL_GRP STRING COMMENT 'NATL_GRP',
  CHAIN STRING COMMENT 'CHAIN',
  CHAIN_NAME STRING COMMENT 'CHAIN_NAME',
  SUB_GROUP STRING COMMENT 'SUB_GROUP',
  SUB_GROUP_NAME STRING COMMENT 'SUB_GROUP_NAME',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_LUTL_PVP_CODING'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_lutl_sales_admin (
  ID STRING COMMENT 'ID',
  DC STRING COMMENT 'DC',
  LOCATION STRING COMMENT 'LOCATION',
  REGION STRING COMMENT 'REGION',
  STATUS STRING COMMENT 'STATUS',
  SALES_ADMIN STRING COMMENT 'SALES_ADMIN',
  MHS_SALES STRING COMMENT 'MHS_SALES',
  DCACM STRING COMMENT 'DCACM',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING
  COMMENT 'Rescued Data',
  ADF_RUN_ID STRING
  COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING
  COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp
  COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING
  COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING
  COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING
  COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME))
  COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME))
  COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_LUTL_SALES_ADMIN'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.T_MNC_PHS (
  CUSTOMER BIGINT COMMENT 'CUSTOMER',
  MEM STRING COMMENT 'MEM',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_MNC_PHS' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_mt_lead_ineligible_list (
  LEAD STRING COMMENT 'LEAD',
  LEAD_NAME STRING COMMENT 'LEAD_NAME',
  COMMENTS STRING COMMENT 'COMMENTS',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_MT_LEAD_INELIGIBLE_LIST' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_mt_override_lead_list (
  CNTRCT_LEAD_ID STRING COMMENT 'CNTRCT_LEAD_ID',
  LEAD_NAME STRING COMMENT 'LEAD_NAME',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_MT_OVERRIDE_LEAD_LIST' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_mt_pvp_report_parentmatch (
  PVP_340B_ID STRING COMMENT 'PVP_340B_ID',
	PVP_MEMBER_NAME STRING COMMENT 'PVP_MEMBER_NAME',
	PVP_PARTICIPANT_ID STRING COMMENT 'PVP_PARTICIPANT_ID',
	PVP_PARTICIPATION_FLAG STRING COMMENT 'PVP_PARTICIPATION_FLAG',
	PVP_EFFECTIVE_DATE STRING COMMENT 'PVP_EFFECTIVE_DATE',
	PVP_EXPIRATION_DATE STRING COMMENT 'PVP_EXPIRATION_DATE',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_MT_PVP_REPORT_PARENTMATCH' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_nat_grp (
RUN_DATE date,
NAT_GRP string,
NAT_SUB_GRP string,
CUST_DSTRCT string,
CUST_RGN string,
ACM string,
DC long,
CAN string,
CAN_NAME string,
CUSID string,
CUS_NAME string,
TERMS string,
TERMS_DESC string,
CHAIN_ string,
PREPAY_DAYS long,
PREPAY double,
PAY_METHOD string,
PAY_METHOD_DESC string,
ADDRESS string,
CITY string,
STATE string,
ZIP string,
DEA string,
DSOP double,
IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
_rescued_data STRING COMMENT 'Rescued Data',
ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_NAT_GRP' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_pharmacy_type_data (
  ID STRING COMMENT 'ID',
  CUST_ACCT STRING COMMENT 'CUST_ACCT',
  CUST_ACCT_NAME STRING COMMENT 'CUST_ACCT_NAME',
  PHS_340BID STRING COMMENT 'PHS_340BID',
  HRSA_COVEREDENTITY STRING COMMENT 'HRSA_COVEREDENTITY',
  CE_NAME STRING COMMENT 'CE_NAME',
  CE_PRIMARY STRING COMMENT 'CE_PRIMARY',
  PHARMACY_TYPE STRING COMMENT 'PHARMACY_TYPE',
  PHARMACY_NAME STRING COMMENT 'PHARMACY_NAME',
  RETAIL_CHAIN STRING COMMENT 'RETAIL_CHAIN',
  CP_PRIMARY STRING COMMENT 'CP_PRIMARY',
  PRIMARY_TPV STRING COMMENT 'PRIMARY_TPV',
  DSCSA_RECEIVED STRING COMMENT 'DSCSA_RECEIVED',
  DATE_CREATED STRING COMMENT 'DATE_CREATED',
  STATUS STRING COMMENT 'STATUS',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING
  COMMENT 'Rescued Data',
  ADF_RUN_ID STRING
  COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING
  COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp
  COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING
  COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING
  COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING
  COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME))
  COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME))
  COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_PHARMACY_TYPE_DATA'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_phs_accounts (
CUST_ACCT_ID BIGINT,
CUST_NAME STRING,
STORE_NUM STRING,
DEA_FAMILY STRING,
DELIVERY_ROUTE_NUM STRING,
DELIVERY_ROUTE_STOP_NUM STRING,
MARKETING_CAMPAIGN STRING,
HOME_DC_ID BIGINT,
DEA_NUM STRING,
HIN_BASE_CD STRING,
HIN_DEPT_CD STRING,
HIN_LOCATION_CD STRING,
HIN_NUM STRING,
ID_340B STRING,
ATTENTION_NAME_DELY STRING,
ADDR_LINE_1_DELY STRING,
ADDR_LINE_2_DELY STRING,
CITY_NAME_DELY STRING,
STATE_CD_DELY STRING,
ZIP_CD_DELY BIGINT,
ATTENTION_NAME_INV STRING,
ADDR_LINE_1_INV STRING,
ADDR_LINE_2_INV STRING,
CITY_NAME_INV STRING,
STATE_CD_INV STRING,
ZIP_CD_INV BIGINT,
CUST_CHAIN_ID BIGINT,
CUST_CHAIN_NAME STRING,
NATIONAL_GROUP_CD BIGINT,
NATIONAL_GROUP_NAME STRING,
NATIONAL_SUB_GROUP_CD BIGINT,
NATIONAL_SUB_GROUP_NAME STRING,
REGION_NUM BIGINT,
REGION_NAME STRING,
DISTRICT_NUM BIGINT,
DISTRICT_NAME STRING,
RX_BILL_PLAN_CD BIGINT,
BUSINESS_TYPE_CD BIGINT,
DISTRIBUTION_CHANNEL BIGINT,
SALES_TERRITORY_ID BIGINT,
PRIMARY_CUST_ID BIGINT,
PROMO_SPEC_PRC_1 STRING,
PROMO_SPEC_PRC_2 STRING,
PROMO_SPEC_PRC_3 STRING,
PROMO_SPEC_PRC_4 STRING,
PROMO_SPEC_PRC_5 STRING,
PROMO_SPEC_PRC_6 STRING,
ACCOUNT_CLASSIFICATION BIGINT,
ACCOUNT_CLASSIFICATION_DESCRIPTION STRING,
IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_PHS_ACCOUNTS' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_phs_accounts_generics (
  ACCOUNTS STRING COMMENT 'ACCOUNTS',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_PHS_ACCOUNTS_GENERICS' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_pvp_report (
PVP_PARTICIPANT_ID BIGINT,
PVP_PARTICIPATION_FLAG BOOLEAN,
COMMITTED_LOP_LOCS STRING,
PVP_ENTITY_TYPE STRING,
PVP_340B_ID STRING,
PVP_PARENT_340B_ID STRING,
HRSA_TERM_CODE STRING,
HRSA_TERM_DATE INTEGER,
PVP_MEMBER_NAME STRING,
PVP_ADDRESS_HEADER STRING,
PVP_ADDRESS_LINE_1 STRING,
PVP_ADDRESS_LINE_2 STRING,
PVP_CITY STRING,
PVP_STATE STRING,
PVP_ZIP_CODE BIGINT,
PVP_ZIP_CODE_EXT BIGINT,
HRSA_MEMBER_DATE INTEGER,
PVP_EFFECTIVE_DATE INTEGER,
PVP_EXPIRATION_DATE INTEGER,
HIN_NUMBER STRING,
COVERED_ENTITY_DEA_NUMBER STRING,
PVP_BILLING_PARTICIPANT_NAME STRING,
PVP_BILLING_ADDRESS1 STRING,
PVP_BILLING_ADDRESS2 STRING,
PVP_BILLING_CITY STRING,
PVP_BILLING_STATE STRING,
PVP_BILLING_ZIP BIGINT,
PVP_BILLING_ZIP2 BIGINT,
PVP_SHIPPING_PARTICIPANT_NAME STRING,
PVP_SHIPPING_ADDRESS1 STRING,
PVP_SHIPPING_ADDRESS2 STRING,
PVP_SHIPPING_CITY STRING,
PVP_SHIPPING_STATE STRING,
PVP_SHIPPING_ZIP STRING,
PVP_SHIPPING_ZIP2 STRING,
PRIME_VENDOR_CONTACT1_NAME STRING,
PRIME_VENDOR_CONTACT1_EMAIL STRING,
PRIME_VENDOR_CONTACT1_TITLE STRING,
PRIME_VENDOR_CONTACT1_TELEPHONE_NUMBER STRING,
PRIME_VENDOR_CONTACT2_NAME STRING,
PRIME_VENDOR_CONTACT2_EMAIL STRING,
PRIME_VENDOR_CONTACT2_TITLE STRING,
PRIME_VENDOR_CONTACT2_TELEPHONE STRING,
PRIME_VENDOR_CONTACT3_NAME STRING,
PRIME_VENDOR_CONTACT3_EMAIL STRING,
PRIME_VENDOR_CONTACT3_TITLE STRING,
PRIME_VENDOR_CONTACT3_TELEPHONE STRING,
ENTITY_MEDICAID_NUMBER STRING,
ENTITY_GRANT_NUMBER STRING,
ALT_METHODS BOOLEAN,
PVP_SHIPPING_HIN STRING,
ORIGINAL_PVP_PARTICIPANT_ID STRING,
IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_PVP_REPORT' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_ta_phmmmd_dm_vstx_cust (
KUNNR_CUST string, 
CUST_ACCT_ID string,
XFD_KU_CK_DGT decimal(38,18),
XFD_KU_BILLING_BLK string,
XFD_KU_AUTH string,
XFD_KU_TELEBOX string,
XFD_KU_INDST_CD_4 string,
XFD_KU_INDST_CD_3 string,
XFD_KU_PBC_REQR string,
XFD_KU_DEA_WARN decimal(38,18),
XFD_KU_DEA_FAMILY string,
XFD_KU_ORIG_DC string,
XFD_KU_CO_IND string,
XFD_KU_ASN_HIER string,
XFD_KU_ASN_FLG_IND string,
XFD_KU_COND_GRP_1 string,
XFD_KU_VAT_REG_NO string,
XFD_KU_PSTNG_BLK string,
XFD_KU_ORD_BLK string,
XFD_KU_LOC_NO_2 decimal(38,18),
XFD_KU_LOC_NO_1 decimal(38,18),
XFD_KU_INDST string,
XFD_KU_DEL_BLK string,
XFD_KU_340B_ID string,
XFD_KU_REGLTORY_DC string,
XFD_KU_PREPAY_ID string,
XFD_KU_PLNOGRM_SIGNAGE string,
XFD_KU_PLNOGRM_CD string,
XFD_KU_INV_REF_CK string,
XFD_KU_PED_REF_TYP string,
XFD_KU_PED_ENA string,
XFD_KU_RTN_PRTOUT string,
MCK_KU_VRITE string,
XFD_KU_DLVRY_BLK string,
XFD_KU_CUST_CLS string,
XFD_KU_ACCT_GRP string,
XFD_KU_CORP_GRP string,
XFD_KU_ATRB_10 string,
XFD_KU_ATRB_1 string,
XFD_KU_ATRB_2 string,
XFD_KU_ATRB_7 string,
XFD_KU_ATRB_3 string,
XFD_KU_INDST_CD_2 string,
XFD_KU_TRNSPORTZON string,
XFD_KU_INDST_CD_1 string,
XFD_KU_EXPR_STN string,
MCK_KU_TERM_RSN string,
MCK_KU_RPTTYP string,
MCK_KU_INVDISCD string,
MCK_KU_SHPLBLTYP string,
MCK_KU_VNDR_TYP string,
MCK_KU_ACTV_DT timestamp,
MCK_KU_INV_DT_EXCL string,
MCK_KU_EQUI_SERV_DT timestamp,
MCK_KU_ITEM_STK_CONF string,
MCK_KU_CONF_TYP string,
MCK_KU_LATEPMT decimal(38,18),
MCK_KU_RX_NONRSLTX decimal(38,18),
MCK_KU_OTC_RSLTX decimal(38,18),
MCK_KU_OTC_NONRSLTX decimal(38,18),
MCK_KU_EXITDATA string,
MCK_KU_HIN_LOC string,
MCK_KU_HIN_DEPT string,
MCK_KU_DOC_NUM string,
MCK_KU_SITEID string,
MCK_KU_EXCLSERVCHRG string,
MCK_KU_PRI_SITEID string,
MCK_KU_DUNLTR string,
MCK_KU_STMT_FREQ string,
MCK_KU_CONSOL_TYP string,
MCK_KU_OSDTXT string,
MCK_KU_CORPCONS string,
MCK_KU_LIMORD decimal(38,18),
MCK_KU_CRD_LIMTOT decimal(38,18),
MCK_KU_TOTESPLIT string,
MCK_KU_DEA_ELIG string,
MCK_KU_WEB_VRITE string,
MCK_KU_ORD_FLTR_CD string,
MCK_KU_ITEM_FLTR_CD string,
MCK_KU_RX_SUB_ADJ2 string,
MCK_KU_RX_SUB_ADJ1 string,
MCK_KU_ERLY_RTE string,
MCK_KU_RX_SUB_ADJ0 string,
MCK_KU_EOE_LAST_QTY string,
MCK_KU_ALT_SRC string,
MCK_KU_SAM string,
MCK_KU_MULTI_SRC string,
MCK_KU_INIT_LOAD timestamp,
MCK_KU_PROMO_END_RSN string,
XFD_KU_TELETEX_1 string,
MCK_KU_MKUP1 decimal(38,18),
MCK_KU_ESTABBY string,
MCK_KU_PRC_TYP string,
MCK_KU_RPTLEADGRP string,
MCK_KU_RPTLEADNAM string,
MCK_KU_MEMNETWKCD string,
MCK_KU_RX_SUB_ADJ5 string,
MCK_KU_MEDST string,
MCK_KU_RX_SUB_ADJ3 string,
MCK_KU_OTCUPD string,
MCK_KU_BIWK string,
MCK_KU_LBLSTK string,
MCK_KU_STORELBL string,
MCK_KU_COST_CD0 string,
MCK_KU_COST_CD6 string,
MCK_KU_COST_CD9 string,
MCK_KU_COST_CD7 string,
XFD_KU_VNDR string,
MCK_KU_COST_CD8 string,
MCK_KU_STAT_CUST_FEP string,
MCK_KU_OTC_SUB_ADJ2 string,
MCK_KU_RX_SUB_ADJ6 string,
MCK_KU_SECR_TCH_TONE string,
MCK_KU_RX_SUB_ADJ7 string,
MCK_KU_CRREQ_CUST string,
MCK_KU_RX_SUB_ADJ8 string,
MCK_KU_PVT_LBL string,
MCK_KU_RX_SUB_ADJ9 string,
MCK_KU_OTC_RTL_DT_CD string,
MCK_KU_RX_SUB_CHAR0 string,
MCK_KU_RX_RTL_DT_CD string,
MCK_KU_RX_SUB_CHAR1 string,
MCK_KU_OTC_RTL_PLN_PCT1 decimal(38,18),
MCK_KU_RX_SUB_CHAR2 string,
MCK_KU_RX_RTL_PLN_PCT1 decimal(38,18),
MCK_KU_RX_SUB_CHAR3 string,
MCK_KU_ALPHA_SORT string,
MCK_KU_RX_SUB_CHAR4 string,
MCK_KU_LIMTOT decimal(38,18),
MCK_KU_RX_SUB_CHAR5 string,
MCK_KU_RX_SUB_CHAR6 string,
MCK_KU_RX_SUB_CHAR7 string,
MCK_KU_COST_CD1 string,
MCK_KU_RX_SUB_CHAR8 string,
MCK_KU_COST_CD2 string,
MCK_KU_RX_SUB_CHAR9 string,
MCK_KU_COST_CD3 string,
MCK_KU_OTC_SUB_ADJ0 string,
MCK_KU_COST_CD4 string,
MCK_KU_PRC_OVR_GRP string,
MCK_KU_PRC_OVR_MTH string,
MCK_KU_PRC_OVR_PCT1 decimal(38,18),
MCK_KU_VKORG string,
MCK_KU_OTC_SUB_ADJ1 string,
XFD_KU_ATRB_8_1 string,
MCK_KU_COST_CD5 string,
MCK_KU_RX_RTL_FMT_CD string,
MCK_KU_OTC_SUB_CHAR0 string,
MCK_KU_OTC_SUB_CHAR1 string,
MCK_KU_RX_SUB_ADJ4 string,
MCK_KU_OTC_SUB_CHAR2 string,
MCK_KU_SPART string,
MCK_KU_SUB_ADJ6 string,
MCK_KU_OTC_SUB_ADJ9 string,
MCK_KU_SUB_CHAR string,
MCK_KU_CUST_PRC_PLN_SPCL_P string,
MCK_KU_CUST_PRC_PLN_SPCL string,
XFD_KU_ALTPAYER string,
MCK_KU_CR_STAT string,
XFD_KU_ATRB_5_1 string,
MCK_KU_PROFL_ITEM string,
XFD_KU_ATRB_4_1 string,
MCK_KU_DEPT_LGTH decimal(38,18),
XFD_KU_ATRB_6_1 string,
MCK_KU_DEPT_FMT string,
MCK_KU_SUB_FLD decimal(38,18),
MCK_KU_ITEM_LGTH decimal(38,18),
MCK_KU_SUB_ADJ string,
MCK_KU_ITEM_FMT string,
MCK_KU_RGN_LGTH decimal(38,18),
MCK_KU_OTC_SUB_ADJ7 string,
MCK_KU_RGN_FMT string,
MCK_KU_OTC_SUB_ADJ8 string,
MCK_KU_ITEM_INPUT1 string,
MCK_KU_OTC_SUB_CHAR4 string,
MCK_KU_OTC_SUB_ADJ6 string,
MCK_KU_OTC_SUB_CHAR3 string,
MCK_KU_OTC_SUB_ADJ5 string,
MCK_KU_CR_MSG string,
MCK_KU_OTC_SUB_ADJ4 string,
MCK_KU_OTC_SUB_CHAR5 string,
MCK_KU_OTC_SUB_ADJ3 string,
MCK_KU_DEPT_INV1 string,
MCK_KU_PRC_STKR_IND string,
MCK_KU_DEPT_INV2 string,
MCK_KU_ITEM_INPUT2 string,
MCK_KU_CUST_INPUT1 string,
MCK_KU_CUST_INPUT2 string,
MCK_KU_ITEM_INV1 string,
MCK_KU_ITEM_INV2 string,
MCK_KU_MCK_DEPT string,
MCK_KU_CUST_DEPT string,
MCK_KU_PREPYMT decimal(38,18),
MCK_KU_CUST_LGTH decimal(38,18),
MCK_KU_DSTRCT_LGTH decimal(38,18),
MCK_KU_CUST_FMT string,
MCK_KU_DSTRCT_FMT string,
MCK_KU_PROMOEND timestamp,
MCK_KU_RPT_GRP_SLS_TAX string,
MCK_KU_SUB_ADJ5 string,
MCK_KU_CNFRM_SEQ string,
MCK_KU_SUB_ADJ0 string,
MCK_KU_CNFRM_RPT string,
MCK_KU_SUB_ADJ8 string,
MCK_KU_SUB_ADJ7 string,
MCK_KU_SUB_ADJ1 string,
MCK_KU_SUB_ADJ4 string,
MCK_KU_SUB_ADJ3 string,
MCK_KU_SUB_ADJ2 string,
MCK_KU_SPCLS string,
MCK_KU_OTC_SUB_CHAR8 string,
MCK_KU_OTC_SUB_CHAR9 string,
MCK_KU_CR_TERMS string,
MCK_KU_DS_XCPT_RX decimal(38,18),
MCK_KU_CUST_DEPT_DESC string,
MCK_KU_DS_XCPT_OTC decimal(38,18),
MCK_KU_MKUP decimal(38,18),
MCK_KU_SVC_PROG_TYP string,
MCK_KU_PRC_OVR_PCT decimal(38,18),
MCK_KU_PICK_CONSOL string,
MCK_KU_ADDBILL_THRESH string,
MCK_KU_PROMO_MGR_RTL string,
MCK_KU_PROCESS_GRP_CD string,
MCK_KU_WRKLD_BAL_EXCL string,
MCK_KU_OTC_RTL_FMT_CD string,
MCK_KU_FMT_PRC_LBL string,
MCK_KU_DLOC_ST_CD string,
MCK_KU_PREFD_CUST string,
MCK_KU_DLOC_REGN string,
MCK_KU_DS_ELIG string,
MCK_KU_RTL_RX_LBL_CONST2 string,
MCK_KU_INV_SPLIT_ORD string,
MCK_KU_DLOC_AREA string,
MCK_KU_OTC_SUB_CHAR6 string,
MCK_KU_DLOC_ABBR string,
MCK_KU_OTC_SUB_CHAR7 string,
MCK_KU_ST_PHARM string,
MCK_KU_HIN_BASE string,
MCK_KU_NCPDP string,
MCK_KU_RTL_RX_LBL_CONST1 string,
MCK_KU_DEA_SEC_EXPIR timestamp,
MCK_KU_PRI_ACCT string,
MCK_KU_PRICING_LEAD string,
MCK_KU_RETL_LEAD string,
MCK_KU_ST_PHARM_EXPIR timestamp,
MCK_KU_MKTG_OPTN string,
MCK_KU_XREF_LEAD string,
MCK_KU_RPT_LEAD string,
MCK_KU_SHIP_FEE_CD_REG string,
MCK_KU_SHIP_FEE_CD_OVRNITE string,
MCK_KU_PO_REQR string,
MCK_KU_OTC_FEE_CD string,
MCK_KU_OTC_RTL_PLN_PCT decimal(38,18),
MCK_KU_RX_FEE_CD string,
MCK_KU_RX_RTL_PLN_PCT decimal(38,18),
XFD_KU_KATR4 string,
XFD_KU_KATR3 string,
MCK_KU_ALIAS string,
XFD_KU_KATR2 string,
MCK_KU_PROMOIDS string,
MCK_KU_CALL_FREQ decimal(38,18),
MCK_KU_OTCDSMKUP decimal(38,18),
MCK_KU_EDI_BILLTYP string,
MCK_KU_RXDSMKUP decimal(38,18),
MCK_KU_NPI string,
MCK_KU_OTC_RTL_LBL_CONST2 string,
MCK_KU_OTC_PROMO_BILL_PLN string,
MCK_KU_SUB_CHAR6 string,
MCK_KU_RX_PROMO_BILL_PLN string,
MCK_KU_SUB_CHAR5 string,
MCK_KU_SHIP_METH string,
MCK_KU_SUB_CHAR4 string,
MCK_KU_RXPROMOMKUP decimal(38,18),
MCK_KU_SUB_CHAR3 string,
MCK_KU_OTC_RTL_LBL_CONST1 string,
MCK_KU_SUB_CHAR2 string,
MCK_KU_PRRTY string,
MCK_KU_SUB_CHAR1 string,
MCK_KU_SUB_CHAR9 string,
MCK_KU_SUB_CHAR0 string,
MCK_KU_SUB_CHAR8 string,
MCK_KU_DEA_SCNDRY string,
MCK_KU_OTCPROMOMKUP decimal(38,18),
MCK_KU_SUB_ADJ9 string,
MCK_KU_OTCMKUP decimal(38,18),
MCK_KU_RXMKUP decimal(38,18),
MCK_KU_OUTPUT_TYP string,
MCK_KU_EQUI_SER string,
MCK_KU_RQRMT decimal(38,18),
MCK_KU_EQUI_MDL string,
MCK_KU_SND_CNCL string,
MCK_KU_DELY_TAX_LOCN string,
MCK_KU_XCLD string,
MCK_KU_TRGT_FMT string,
MCK_KU_MANL string,
MCK_KU_TRGT_ID string,
MCK_KU_SLPS_TER_RSN string,
MCK_KU_TRGT_SYS string,
MCK_KU_SLPS_RX_OVR_IND string,
MCK_KU_SUB_CHAR7 string,
MCK_KU_CRD_RVW_DT string,
MCK_KU_DLOC_DCTYP string,
MCK_KU_DLOC_ALLOC_STAT string,
MCK_KU_CHNL_TYP string,
MCK_KU_DLOC_MRG_STAT string,
MCK_KU_GPO string,
MCK_KU_DLOC_FILENO string,
MCK_KU_SLPS_OTC_OVR_IND string,
MCK_KU_DLOC_CYCLNUM string,
MCK_KU_SLPS_CP string,
MCK_KU_RPTLEAD string,
MCK_KU_SLPS_MIN_QTY string,
XFD_KU_TRAIN_STN string,
MCK_KU_START_DT timestamp,
MCK_KU_DEA_EXPIR timestamp,
MCK_KU_VAR_PRC_REP string,
MCK_KU_CRD_LIMTOT_1 decimal(38,18),
MCK_KU_EFF_ENDDT timestamp,
MCK_KU_SLPS_L_STK string,
MCK_KU_ST_CS_LCNS string,
MCK_KU_SLPS_SS_CD string,
MCK_KU_ST_CS_LCNS_EXPIR timestamp,
MCK_KU_CNTRC_CBREFNUM string,
XFD_KU_CSOS_CK_ACTV string,
MCK_KU_CNTRC_VNDRNAM string,
MCK_KU_SLPS_LAYOUT string,
MCK_KU_CSMK_CHG decimal(38,18),
MCK_KU_AREARGN string,
MCK_KU_LCNS_TYP string,
MCK_KU_SLPS_L_TYP string,
MCK_KU_PRTNR string,
MCK_KU_SLPS_SS_OVR_IND string,
MCK_KU_CRD_LIMTOT_2 decimal(38,18),
MCK_KU_LCNS_TYP_DES string,
MCK_KU_DIST_CUST string,
MCK_KU_CUST_CR_RT string,
MCK_KU_E222_DEA_ASSN string,
MCK_KU_RAM string,
MCK_KU_DEA_CLS string,
MCK_KU_ACCT_STAT string,
MCK_KU_CUST_DUNS_RT string,
MCK_KU_CNTRC_COMM string,
MCK_KU_COLL_AGCY string,
MCK_KU_CNTRC_CDKEY string,
MCK_KU_CR_MGR string,
MCK_KU_RX_RSLTX decimal(38,18),
MCK_KU_CR_LIM_RVW_NEXT_YM decimal(38,18),
MCK_KU_ORD_CONFRM_PH decimal(38,18),
MCK_KU_RASR string,
MCK_KU_PROMOSTART timestamp,
MCK_KU_OPRGRP string,
MCK_KU_BNS_GOODS_QUAL string,
MCK_KU_CSMK_CD string,
MCK_KU_RXOTC_IND string,
MCK_KU_VAT_REG_NO_EXPIR timestamp,
MCK_KU_SLPS_RX_IND string,
MCK_KU_PCT_REBT decimal(38,18),
MCK_KU_SLPS_OTC_IND string,
MCK_KU_EDI_CORR_ID string,
MCK_KU_RPAR_CUST string,
MCK_KU_VNDR string,
MCK_KU_WHSLR string,
MCK_KU_CR_AUTH_TYP string,
MCK_KU_FUTR_OF_SCRPT string,
MCK_KU_CHN string,
MCK_KU_MRKT_CMPGN string,
MCK_KU_CHN_DUMMY string,
MCK_KU_NATL_GRP_DUMMY string,
MCK_KU_SUB_GRP_DUMMY string,
MCK_KU_CUST_RGN_DUMMY string,
MCK_KU_CUST_DSTRCT_DUMMY string,
MCK_KU_CHN_DUMMY_DESC string,
MCK_KU_NAT_GRP_DUMMY_DESC string,
MCK_KU_SUB_GRP_DUMMY_DESC string,
MCK_KU_CUST_RGN_DUMMY_DESC string,
MCK_KU_CUST_DIST_DUMMY_DESC string,
MCK_KU_CR_AUTH_REQ_FLG timestamp,
MCK_KU_CUST_LIST_NUM string,
MCK_KU_CUST_LIST_RQSTR string,
MCK_KU_CASH_DSCNT_FLG string,
MCK_KU_INTEREST_IND_TYP string,
MCK_KU_CR_MGR_USR_NAM string,
MCK_KU_CR_TERMS_PLASMA string,
MCK_KU_CASH_DSCNT_FLG_PLSM string,
MCK_KU_LATEPMT_PLASMA decimal(38,18),
MCK_KU_INVDISCD_PLASMA string,
MCK_KU_FORM_REQ_TYP string,
MCK_KU_EXPLANATION string,
MCK_KU_RX_HIER_OPT string,
MCK_KU_OTC_HIER_OPT string,
MCK_KU_COID string,
MCK_KU_CORRID string,
MCK_KU_EDIDOCTYP string,
MCK_KU_EDIPICKTYP string,
MCK_KU_GRPID string,
MCK_KU_PROMOID string,
MCK_KU_PROMOID_1 string,
MCK_KU_RMDY_REQ_NUM string,
MCK_KU_RMDY_RQSTR string,
MCK_KU_INVCPY_CTRLD decimal(38,18),
MCK_KU_CR_CUST string,
MCK_KU_EXT_ORDERING string,
MCK_KU_LYNX_PARENT_ACCOUNT string,
MCK_KU_DSCSA string,
MCK_KU_ACCT_CLAS string,
MCK_KU_ACCT_CLAS_DESC string,
MCK_KU_GPOS string,
MCK_KU_GPOS_DESC string,
MCK_KU_GPO_ACCT string,
MCK_KU_GOVT_CONTRACT_IND string,
IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
_rescued_data STRING COMMENT 'Rescued Data',
ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_TA_PHMMMD_DM_VSTX_CUST'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_tpv (
  ID STRING COMMENT 'ID',
  VENDOR_NAME STRING COMMENT 'VENDOR_NAME',
  TPV STRING COMMENT 'TPV',
  ACCOUNT_MANAGER STRING COMMENT 'ACCOUNT_MANAGER',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING
  COMMENT 'Rescued Data',
  ADF_RUN_ID STRING
  COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING
  COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp
  COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING
  COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING
  COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING
  COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME))
  COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME))
  COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_TPV'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_apexus_code_key (
  LEAD_NO BIGINT,
  CODE_KEY BIGINT,
  ORG_ID_SEQ STRING,
  CONTRACT_NAME STRING,
  VENDOR_NO BIGINT,
  VENDOR_NAME STRING,
  MATERIAL BIGINT,
  EAN_UPC STRING,
  MATERIAL_DESCRIPTION STRING,
  ORIGINAL_VALID_FROM INTEGER,
  ORIGINAL_VALID_TO INTEGER,
  BID_PRICE DOUBLE,
  VARIANCE STRING,
  WAC DOUBLE,
  NO_CHARGEBACK_INDICATOR STRING,
  GPO_CHBK_REF_NO STRING,
  GENERIC_FLAG STRING,
  ITEM_STATUS STRING,
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING
  COMMENT 'Rescued Data',
  ADF_RUN_ID STRING
  COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING
  COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp
  COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING
  COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING
  COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING
  COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME))
  COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME))
  COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_APEXUS_CODE_KEY'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles' = true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.T_APEXUS_PHS_ACCT_BY_LEAD (
    LEAD_NO BIGINT,
    CODE_KEY string,
    ORG_ID_SEQ STRING,
    CONTRACT_NAME STRING,
    VENDOR_NO BIGINT,
    VENDOR_NAME STRING,
    MATERIAL BIGINT,
    EAN_UPC STRING,
    MATERIAL_DESCRIPTION STRING,
    ORIGINAL_VALID_FROM INTEGER,
    ORIGINAL_VALID_TO INTEGER,
    BID_PRICE DOUBLE,
    VARIANCE DOUBLE,
    WAC DOUBLE,
    NO_CHARGEBACK_INDICATOR STRING,
    GPO_CHBK_REF_NO STRING,
    GENERIC_FLAG STRING,
    ITEM_STATUS STRING,
    IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_APEXUS_PHS_ACCT_BY_LEAD' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.T_PHS_ACCOUNTS_NON_AGP (
    Accounts STRING,
    IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_PHS_ACCOUNTS_NON_AGP' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.T_APEXUS_WAC_ACCT_BY_LEAD (
    LEAD_NO BIGINT,
    CODE_KEY STRING,
    ORG_ID_SEQ STRING,
    CONTRACT_NAME STRING,
    VENDOR_NO BIGINT,
    VENDOR_NAME STRING,
    MATERIAL BIGINT,
    EAN_UPC STRING,
    MATERIAL_DESCRIPTION STRING,
    ORIGINAL_VALID_FROM INTEGER,
    ORIGINAL_VALID_TO INTEGER,
    BID_PRICE DOUBLE,
    VARIANCE DOUBLE,
    WAC DOUBLE,
    NO_CHARGEBACK_INDICATOR STRING,
    GPO_CHBK_REF_NO STRING,
    GENERIC_FLAG STRING,
    ITEM_STATUS STRING,
    IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_APEXUS_WAC_ACCT_BY_LEAD' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_apexusfile (
  ID STRING COMMENT 'ID',
  APEXUS_340B_ID STRING COMMENT 'APEXUS_340B_ID',
  ENTITY_NAME STRING COMMENT 'ENTITY_NAME',
  SHIP_TO_ACCT_NAME STRING COMMENT 'SHIP_TO_ACCT_NAME',
  SHIP_TO_ACCT_NO BIGINT COMMENT 'SHIP_TO_ACCT_NO',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_APEXUSFILE' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.t_iw_cust_acct (
CUST_ACCT_ID string,
CUST_NUM string,
CUST_BUS_TYP_CD string,
SLS_TERR_ID string,
PRI_FILL_DC_ID string,
NATL_ACCT_ID string,
CUST_ACCT_NAM string,
HIN_NUM string,
PRI_ACCT_IND  string,
DLVRY_RTE_NUM string,
DLVRY_RTE_STOP_NUM string,
VRITE_BUS_TYP_CD string,
VRITE_REBT_IND string,
ACCT_DLVRY_ADDR string,
ACCT_DLVRY_CTY_NAM string,
ACCT_DLVRY_ST_ABRV string,
ACCT_DLVRY_ZIP string,
ACCT_DLVRY_ZIP_SFX string,
HOME_DC_ID string,
HOME_DC_DSCR string,
SLSPRSN_ID string,
NATL_ACCT_DSCR string,
PRI_FILL_DC_DSCR string,
NABP_NUM string,
DEA_NUM string,
VRITE_CUST_IND string,
CUST_CHN_ID string,
CUST_STOR_NUM string,
ACCT_DLVRY_AREA_CD string,
ACCT_DLVRY_PH_NUM string,
ACTIVE_CUST_IND string,
XTRCT_DT string,
CR_STAT_CD string,
DEA_NUM_EXPIR_DT string,
ST_PHARM_LCNS_NUM string,
MDCD_ST_ABRV string,
DLVRY_ATTN_NAM string,
CR_LMT_DLLR_AMT integer,
PMT_TRMS_CD string,
CUR_DUE_DLLR_AMT decimal(38,18),
TOT_DUE_DLLR_AMT decimal(38,18),
MS_SCHM_ID string,
CUST_RGN_NUM string,
CUST_DSTRCT_NUM string,
CUST_CMAX_IND string,
CUST_OMNI_IND string,
CUST_SEL_GNRC_IND string,
MCK_ACCT_VNDR_CD string,
NATL_GRP_CD string,
NATL_SUB_GRP_CD string,
ACCT_SVC_ELIG_BEG_DT timestamp,
ACCT_SVC_ELIG_END_DT timestamp,
ACCT_CHN_ID string,
ALT_SRC_ID string,
CUST_ACCT_HIN_BASE_CD string,
CUST_ACCT_HIN_LOC_CD string,
CUST_ACCT_HIN_DEPT_CD string,
ORDFLTR_CUSTGRP_ID string,
ORDR_ITEM_FLTR_CD string,
DLVRY_DOC_IND string,
CUST_ASGN_MCK_IND string,
INVC_FMT_CD string,
INVC_SUM_TYP_CD string,
MCK_CO_CD string,
CUST_LOC_ID string,
ACCT_LOC_ID string,
ACCT_STOR_NUM string,
RETL_ACCT_MNGR_ID string,
RETL_ACCT_SVC_REP_ID string,
NPI_NUM string,
SITE_ID string,
PRI_SITE_IND string,
SRC_ID_MULT string,
CUST_TYPE_BUS string,
ITEM_CNTRL1 string,
ITEM_CNTRL2 string,
ITEM_CNTRL3 string,
ITEM_CNTRL4 string,
ITEM_CNTRL5 string,
ITEM_CNTRL6 string,
ITEM_CNTRL7 string,
ITEM_CNTRL8 string,
DELY_FEE string,
AR_PPD string,
CUST_SVC_BEG2 string,
CUST_SVC_END3 string,
DEA_CRN_EXP_DT string,
DEA_CHEM_REG_NO string,
NEW_MAIL_NAME string,
FAX_CUST_AREA string,
ADR_CUST_DELY2 string,
ITEM_PVT_LBL string,
FILLER string,
SRC_ID_MULT1 string,
CUST_GRP string,
DEA_NUM_SH string,
IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_IW_CUST_ACCT'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS   psas_di_dev.340b_brnz.T_MPB_PHS_WAC_TEMP (
	CUSTOMER BIGINT,
	COCD BIGINT,
	DATE DATE,
	NAME_1 STRING,
	NAME_2 STRING,
	STREET STRING,
	CITY STRING,
	RG STRING,
	POSTALCODE STRING,
	340B_CONTRACT_PHARMACY_ACCOUNT STRING,
	340B_ID STRING,
	TYPE_OF_BUSINESS STRING,
	CUSTOMER_CLASSIFICATION STRING,
	CL BIGINT,
	DELF STRING,
	ORBLK STRING,
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_MPB_PHS_WAC_TEMP'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS   psas_di_dev.340b_brnz.T_TRACKER_TEMP (
ID BIGINT,
PRIMARY_TPV STRING,
ACCT_MANAGER STRING,
TPV_CONTACT STRING,
SECONDARY_TPV STRING,
EXISTING_ACCT_TO_MIRROR STRING,
DATE_VENDOR_REQUESTED DATE,
DATE_SENT_FOR_APPROVAL DATE,
ID_340B STRING,
PVP_ID STRING,
CE_A_MCK_CUST STRING,
COVERED_ENTITY STRING,
CP_A_MCK_CUST STRING,
CONTRACT_PHARMACY_NAME STRING,
CP_STORE STRING,
DSCSA_REQUESTED STRING,
MPB_REQUESTED_W_PACKET STRING,
DEA_FAMILY_OF_EXISTING_ACCT STRING,
DEA_WARNING_OF_EXISTING_ACCT STRING,
HRSA_ELIGIBILITY_DATE DATE,
MCK_DC STRING,
VPGM STRING,
RETAIL_AND_MHS_SA_CONTACT STRING,
FIELD_ACCT_MANAGER STRING,
ACCOUNT BIGINT,
ACCOUNT_NAME STRING,
DATE_CONTRACTS_CONNECT_ACCESS_REQUESTED DATE,
DATE_EDI_REQUESTED DATE,
ACCOUNT_SET_UP_NOTES STRING,
DATE_CSMP_LOAD_REQUESTED DATE,
DATE_EDI_CREDITS_REQUESTED_WALMART_ONLY STRING,
APEXUS_ID STRING,
CE_ACCOUNT_NUMBER_EXISTING STRING,
CE_ACCOUNT_NAME_EXISTING STRING,
COVERED_ENTITY_DEA STRING,
COVERED_ENTITY_STREET_ADDRESS STRING,
COVERED_ENTITY_CITY STRING,
COVERED_ENTITY_STATE STRING,
COVERED_ENTITY_ZIP_CODE STRING,
COVERED_ENTITY_PHONE_NUMBER STRING,
CP_DEA STRING,
CONTRACT_PHARM_STREET_ADDRESS STRING,
CONTRACT_PHARM_CITY STRING,
CONTRACT_PHARM_STATE STRING,
CONTRACT_PHARM_ZIP_CODE STRING,
CONTRACT_PHARM_PHONE STRING,
CP_COG STRING,
CP_CHAIN BIGINT,
CP_NATIONAL_GROUP STRING,
CP_SUBGROUP STRING,
CP_REGION STRING,
CP_DISTRICT STRING,
PACKET_SENT_TO_DC long,
ITEM_TYPE STRING,
Path STRING,
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_TRACKER_TEMP'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_brnz.T_PHS_MEMBERSHIPROSTER_WAC (
CUST_ACCT_ID STRING,
CUST_NAME STRING,
340B_ID STRING,
PVP_PARTICIPANT_ID STRING,
PVP_PARTICIPATION_FLAG STRING,
PVP_MEMBER_NAME STRING,
PVP_EFFECTIVE_DATE STRING,
PVP_EXPIRATION_DATE STRING,
STORE_NUM STRING,
DEA_FAMILY STRING,
MARKETING_CAMPAIGN STRING,
HOME_DC_ID STRING,
DEA_NUM STRING,
HIN_BASE_CD STRING,
HIN_DEPT_CD STRING,
HIN_LOCATION_CD STRING,
HIN_NUM STRING,
ATTENTION_NAME_DELY STRING,
ADDR_LINE_1_DELY STRING,
ADDR_LINE_2_DELY STRING,
CITY_NAME_DELY STRING,
STATE_CD_DELY STRING,
ZIP_CD_DELY STRING,
ATTENTION_NAME_INV STRING,
ADDR_LINE_1_INV STRING,
ADDR_LINE_2_INV STRING,
CITY_NAME_INV STRING,
STATE_CD_INV STRING,
ZIP_CD_INV STRING,
CUST_CHAIN_ID STRING,
CUST_CHAIN_NAME STRING,
NATIONAL_GROUP_CD STRING,
NATIONAL_GROUP_NAME STRING,
NATIONAL_SUB_GROUP_CD STRING,
NATIONAL_SUB_GROUP_NAME STRING,
REGION_NUM STRING,
REGION_NAME STRING,
DISTRICT_NUM STRING,
DISTRICT_NAME STRING,
RX_BILL_PLAN_CD STRING,
BUSINESS_TYPE_CD STRING,
DISTRIBUTION_CHANNEL STRING,
SALES_TERRITORY_ID STRING,
PRIMARY_CUST_ID STRING,
3RD_PARTY_VENDOR STRING,
SECONDARY_VENDOR STRING,
OTHER_VENDORS STRING,
ACCOUNT_CLASSIFICATION STRING,
ACCOUNT_CLASSIFICATION_DESCRIPTION STRING,
IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
)USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_PHS_MEMBERSHIPROSTER_WAC'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS  psas_di_dev.340b_brnz.T_QUARTERLY_AUDIT_DATA(
STATUS STRING,
GPO STRING,
GROUP_NAME STRING,
CHAIN STRING,
ACCT_CHAIN_NAME STRING,
NATIONAL_GROUP_CD STRING,
NATIONAL_GROUP_NAM STRING,
NATIONAL_SUB_GROUP_CD STRING,
NATIONAL_SUB_GROUP_NAME STRING,
REGION_NUM STRING,
REGION_NAME STRING,
DISTRICT_NUM STRING,
DISTRICT_NAME STRING,
DEA_NUM STRING,
DEA_NUM_EXPIRE STRING,
DEA_FAMILY STRING,
CS_LICENSE STRING,
STATE_PHARMACY_LICENSE_NUM STRING,
STATE_PHARMACY_LICENSE_NUM_EXPIRE STRING,
HIM_NUM STRING,
PHS_340B_ID STRING,
PHS_CONTRACTPHARMA STRING,
PHS_IND STRING,
PHS_PVP STRING,
PHS_AGMT_CD STRING,
ACCT_CLASS_DESC STRING,
NCPDP STRING,
NPI STRING,
AUDITED STRING,
AUDIT_STATUS STRING,
COMMENTS STRING,
CUST_ACCT_ID STRING,
CUST_NAME STRING,
HOME_DC_ID STRING,
DC_DESC STRING,
ADDRESS_DELIVERY STRING,
ADDRESS_STATE STRING,
PRIMARY_CUST_ID STRING,
PRIMARY_SECONDARY_ STRING,
ALIAS STRING,
SERVICE_ELIGIBILITY_BEGIN STRING,
SERVICE_ELIGIBILITY_END STRING,
SALES_TERRITORY_ID STRING,
SALESPERSON STRING,
AM_OR_RSM STRING,
VPS_NAME STRING,
VPGM STRING,
ACM STRING,
CAN_NUMBER STRING,
CAN_NAME STRING,
PRE_PAY_DAYS STRING,
PREPAY_BY_CAN STRING,
CASH_DISCOUNT_FLAG STRING,
PAY_METHOD STRING,
PAY_METHOD_DESC STRING,
PAYMENT_TERMS_CD STRING,
PAYMENT_TERMS_DESC STRING,
DSO STRING,
ADP STRING,
MIN_DSO STRING,
MAX_DSO STRING,
PAYMENT_TYPE STRING,
DUE_DATE STRING,
RX_BILL_PLAN_CD STRING,
RX_BILL_PLAN STRING,
RX_PROMO_BP STRING,
RX_PROMO_COG STRING,
OTC_BILL_PLAN_CD STRING,
OTC_BILL_PLAN STRING,
OTC_PROMO_BP STRING,
OTC_PROMO_COG STRING,
CUST_DROP_SHIP_IND STRING,
DROP_SHIP_RX_BILL_ STRING,
DROP_SHIP_OTC_BILL STRING,
SALES_AGREEMENT_TY STRING,
AGREEMENT_EXPIRATION STRING,
MCF_NUM STRING,
AGREEMENT STRING,
ROUTE STRING,
STOP STRING,
TOTAL_DELIVERIES STRING,
COGS_DIFF STRING,
NEW_RX_COGS STRING,
NEW_OTC_COGS STRING,
NET_MONTHLY_AVERAG STRING,
DISTRIBUTION_CHANN STRING,
BUS_TYPE_CD STRING,
BUS_TYPE_DESC STRING,
RETURNS_MATRIX STRING,
FUEL_SURCHARGE STRING,
REDS_FEE_PLAN STRING,
FREE_REDS_PER_MONT STRING,
IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_QUARTERLY_AUDIT_DATA'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.`340b_brnz`.t_chain_lookup (
  CHAIN_ID STRING,
  CHAIN_NAM STRING,
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_CHAIN_LOOKUP'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.`340b_brnz`.t_natl_grp_loookup (
  NATL_GRP_ID STRING,
  NATL_GRP_NAM STRING,
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_NATL_GRP_LOOKUP'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE psas_di_dev.340b_brnz.T_OPACE_DAILY_PUBLIC (
  Grant_Number STRING,
  Site_ID STRING,
  Medicare_Provider_Number STRING,
  `340B_ID` STRING,
  CE_ID STRING,
  Program_Code STRING,
  Participating STRING,
  Participating_Start_Date STRING,
  Term_Date STRING,
  Termination_Code STRING,
  Entity_Name STRING,
  Entity_Sub_Division_Name STRING,
  Address_1 STRING,
  Address_2 STRING,
  Address_3 STRING,
  City STRING,
  State STRING,
  Zip STRING,
  Second_Zip STRING,
  Medicaid_Number STRING,
  NPI STRING,
  Billing_Organization STRING,
  Billing_Address_1 STRING,
  Billing_Address_2 STRING,
  Billing_City STRING,
  Billing_State STRING,
  Billing_Zip STRING,
  Billing_Second_Zip STRING,
  Shipping_Organization STRING,
  Shipping_Address_1 STRING,
  Shipping_Address_2 STRING,
  Shipping_City STRING,
  Shipping_State STRING,
  Shipping_Zip STRING,
  Shipping_Second_Zip STRING,
  Authorizing_Official_Name STRING,
  Authorizing_Official_Title STRING,
  Authorizing_Official_Tel STRING,
  Authorizing_Official_Tel_Ext STRING,
  Contact_Name STRING,
  Contact_Title STRING,
  Contact_Telephone STRING,
  Contact_Telephone_Ext STRING,
  Signed_By_Name STRING,
  Signed_By_Title STRING,
  Signed_By_Telephone STRING,
  Signed_By_Telephone_Ext STRING,
  Signed_By_Date STRING,
  `Certified/Decertified_Date` STRING,
  Rural STRING,
  Entry_Comments STRING,
  Nature_Of_Support STRING,
  Pharmacy_Name STRING,
  Pharmacy_Begin_Date STRING,
  Pharmacy_Term_Date STRING,
  Pharmacy_Address_1 STRING,
  Pharmacy_Address_2 STRING,
  Pharmacy_City STRING,
  Pharmacy_State STRING,
  Pharmacy_Zip STRING,
  Pharmacy_Second_Zip STRING,
  Pharmacy_Comments STRING,
  Pharmacy_Telephone STRING,
  Pharmacy_Telephone_Ext STRING,
  Contract_Pharmacy_Comments STRING,
  Edit_Date STRING,
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/brnz/T_OPACE_DAILY_PUBLIC'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);
