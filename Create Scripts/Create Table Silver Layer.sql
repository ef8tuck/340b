-- Databricks notebook source
CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_account_mnc_list (
  CUST_ACCT_ID STRING COMMENT 'CUST_ACCT_ID',
  MNC_CODE STRING COMMENT 'MNC_CODE',
  IS_ACTIVE STRING DEFAULT 'Y' COMMENT 'Indicates if the record is active, default is Y',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_ACCOUNT_MNC_LIST' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_activestatusupdate (
  CUST_ACCT_ID STRING COMMENT 'CUST_ACCT_ID',
  CUST_ACCT_NAME STRING COMMENT 'CUST_ACCT_NAME',
  ACCT_CLASS STRING COMMENT 'ACCT_CLASS',
  STATUS STRING COMMENT 'STATUS',
  ACTIVE_STATUS_UPDATE STRING COMMENT 'ACTIVE_STATUS_UPDATE',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_ACTIVESTATUSUPDATE' 
TBLPROPERTIES (
 'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.T_CHAINS (
  ID STRING COMMENT 'ID',
 CHAIN STRING COMMENT 'CHAIN',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_CHAINS' 
TBLPROPERTIES (
 'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_contractpharmacy_exceptions (
  ID STRING COMMENT 'ID',
  RETAIL_CHAIN STRING COMMENT 'RETAIL_CHAIN',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_CONTRACTPHARMACY_EXCEPTIONS' 
TBLPROPERTIES (
 'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_gpo_managers (
  GPO_NAME STRING COMMENT 'GPO_NAME',
  SENIOR_ACCOUNT_MANAGER STRING COMMENT 'SENIOR_ACCOUNT_MANAGER',
  ACCOUNT_MANAGER_SUPPORT STRING COMMENT 'ACCOUNT_MANAGER_SUPPORT',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_GPO_MANAGERS' 
TBLPROPERTIES (
 'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_luq_account (
  ID STRING COMMENT 'ID',
  ACCOUNT STRING COMMENT 'ACCOUNT',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_LUQ_ACCOUNT' 
TBLPROPERTIES (
 'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

 CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_lutl_entity (
  ID STRING COMMENT 'ID',
  ENTITY_TYPE STRING COMMENT 'ENTITY_TYPE',
  ENTITY_NAME STRING COMMENT 'ENTITY_NAME',
  EXPANSION_ENTITY STRING COMMENT 'EXPANSION_ENTITY',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_LUTL_ENTITY' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_lutl_non_ordering_accounts (
  ID STRING COMMENT 'ID',
  CUST_ACCT_ID STRING COMMENT 'CUST_ACCT_ID',
  CUST_ACCT_NAME STRING COMMENT 'CUST_ACCT_NAME',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_LUTL_NON_ORDERING_ACCOUNTS'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.T_LUTL_PHS_LEADS (
  ID STRING COMMENT 'ID',
  LEAD STRING COMMENT 'LEAD',
  LEAD_NAME STRING COMMENT 'LEAD_NAME',
  Apexus STRING COMMENT 'Apexus',
  PVP_Flag STRING COMMENT 'PVP_Flag',
  PHS STRING COMMENT 'PHS',
  WAC STRING COMMENT 'WAC',
  Expansion STRING COMMENT 'Expansion',
  DMEM_Org STRING COMMENT 'DMEM_Org',
  DMEM_Id STRING COMMENT 'DMEM_Id',
  DMEM_Seq STRING COMMENT 'DMEM_Id',
  DMEM_Prio STRING COMMENT 'DMEM_Prio',
  DMEM_Pref STRING COMMENT 'DMEM_Pref',
  AGP STRING COMMENT 'AGP',
  LEAD_Unformatted STRING,
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_LUTL_PHS_LEADS'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

 CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_lutl_pvp_coding (
  ID STRING COMMENT 'ID',
  CODING STRING COMMENT 'CODING',
  PVP_CODING STRING COMMENT 'PVP_CODING',
  NATL_GRP STRING COMMENT 'NATL_GRP',
  CHAIN STRING COMMENT 'CHAIN',
  CHAIN_NAME STRING COMMENT 'CHAIN_NAME',
  SUB_GROUP STRING COMMENT 'SUB_GROUP',
  SUB_GROUP_NAME STRING COMMENT 'SUB_GROUP_NAME',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_LUTL_PVP_CODING'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_lutl_sales_admin (
  ID STRING COMMENT 'ID',
  DC STRING COMMENT 'DC',
  LOCATION STRING COMMENT 'LOCATION',
  REGION STRING COMMENT 'REGION',
  STATUS STRING COMMENT 'STATUS',
  SALES_ADMIN STRING COMMENT 'SALES_ADMIN',
  MHS_SALES STRING COMMENT 'MHS_SALES',
  DCACM STRING COMMENT 'DCACM',
  _rescued_data STRING
  COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_LUTL_SALES_ADMIN'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_mnc_phs (
  CUSTOMER BIGINT COMMENT 'CUSTOMER',
  MEM STRING COMMENT 'MEM',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_MNC_PHS' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_mt_lead_ineligible_list (
  LEAD STRING COMMENT 'LEAD',
  LEAD_NAME STRING COMMENT 'LEAD_NAME',
  COMMENTS STRING COMMENT 'COMMENTS',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_MT_LEAD_INELIGIBLE_LIST' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_mt_override_lead_list (
  CNTRCT_LEAD_ID STRING COMMENT 'CNTRCT_LEAD_ID',
  LEAD_NAME STRING COMMENT 'LEAD_NAME',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_MT_OVERRIDE_LEAD_LIST' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_mt_pvp_report_parentmatch (
  PVP_340B_ID STRING COMMENT 'PVP_340B_ID',
	PVP_MEMBER_NAME STRING COMMENT 'PVP_MEMBER_NAME',
	PVP_PARTICIPANT_ID INTEGER COMMENT 'PVP_PARTICIPANT_ID',
	PVP_PARTICIPATION_FLAG STRING COMMENT 'PVP_PARTICIPATION_FLAG',
	PVP_EFFECTIVE_DATE DATE COMMENT 'PVP_EFFECTIVE_DATE',
	PVP_EXPIRATION_DATE DATE COMMENT 'PVP_EXPIRATION_DATE',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_MT_PVP_REPORT_PARENTMATCH' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_nat_grp (
RUN_DATE DATE,
NAT_GRP STRING,
NAT_SUB_GRP STRING,
CUST_DSTRCT STRING,
CUST_RGN STRING,
ACM STRING,
DC BIGINT,
CAN STRING,
CAN_NAME STRING,
CUSID STRING,
CUS_NAME STRING,
TERMS STRING,
TERMS_DESC STRING,
CHAIN_ STRING,
PREPAY_DAYS BIGINT,
PREPAY DOUBLE,
PAY_METHOD STRING,
PAY_METHOD_DESC STRING,
ADDRESS STRING,
CITY STRING,
STATE STRING,
ZIP STRING,
DEA STRING,
DSOP DOUBLE,
_rescued_data STRING COMMENT 'Rescued Data',
ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_NAT_GRP' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_pharmacy_type_data (
  ID STRING COMMENT 'ID',
  CUST_ACCT STRING COMMENT 'CUST_ACCT',
  CUST_ACCT_NAME STRING COMMENT 'CUST_ACCT_NAME',
  PHS_340BID STRING COMMENT 'PHS_340BID',
  HRSA_COVEREDENTITY STRING COMMENT 'HRSA_COVEREDENTITY',
  CE_NAME STRING COMMENT 'CE_NAME',
  CE_PRIMARY STRING COMMENT 'CE_PRIMARY',
  PHARMACY_TYPE STRING COMMENT 'PHARMACY_TYPE',
  PHARMACY_NAME STRING COMMENT 'PHARMACY_NAME',
  RETAIL_CHAIN STRING COMMENT 'RETAIL_CHAIN',
  CP_PRIMARY STRING COMMENT 'CP_PRIMARY',
  PRIMARY_TPV STRING COMMENT 'PRIMARY_TPV',
  DSCSA_RECEIVED STRING COMMENT 'DSCSA_RECEIVED',
  DATE_CREATED STRING COMMENT 'DATE_CREATED',
  STATUS STRING COMMENT 'STATUS',
  _rescued_data STRING
  COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_PHARMACY_TYPE_DATA'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_phs_accounts (
CUST_ACCT_ID BIGINT,
CUST_NAME STRING,
STORE_NUM STRING,
DEA_FAMILY STRING,
DELIVERY_ROUTE_NUM STRING,
DELIVERY_ROUTE_STOP_NUM STRING,
MARKETING_CAMPAIGN STRING,
HOME_DC_ID BIGINT,
DEA_NUM STRING,
HIN_BASE_CD STRING,
HIN_DEPT_CD STRING,
HIN_LOCATION_CD STRING,
HIN_NUM STRING,
ID_340B STRING,
ATTENTION_NAME_DELY STRING,
ADDR_LINE_1_DELY STRING,
ADDR_LINE_2_DELY STRING,
CITY_NAME_DELY STRING,
STATE_CD_DELY STRING,
ZIP_CD_DELY BIGINT,
ATTENTION_NAME_INV STRING,
ADDR_LINE_1_INV STRING,
ADDR_LINE_2_INV STRING,
CITY_NAME_INV STRING,
STATE_CD_INV STRING,
ZIP_CD_INV BIGINT,
CUST_CHAIN_ID BIGINT,
CUST_CHAIN_NAME STRING,
NATIONAL_GROUP_CD BIGINT,
NATIONAL_GROUP_NAME STRING,
NATIONAL_SUB_GROUP_CD BIGINT,
NATIONAL_SUB_GROUP_NAME STRING,
REGION_NUM BIGINT,
REGION_NAME STRING,
DISTRICT_NUM BIGINT,
DISTRICT_NAME STRING,
RX_BILL_PLAN_CD BIGINT,
BUSINESS_TYPE_CD BIGINT,
DISTRIBUTION_CHANNEL BIGINT,
SALES_TERRITORY_ID BIGINT,
PRIMARY_CUST_ID BIGINT,
PROMO_SPEC_PRC_1 STRING,
PROMO_SPEC_PRC_2 STRING,
PROMO_SPEC_PRC_3 STRING,
PROMO_SPEC_PRC_4 STRING,
PROMO_SPEC_PRC_5 STRING,
PROMO_SPEC_PRC_6 STRING,
ACCOUNT_CLASSIFICATION BIGINT,
ACCOUNT_CLASSIFICATION_DESCRIPTION STRING,
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_PHS_ACCOUNTS' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_phs_accounts_generics (
  ACCOUNTS STRING COMMENT 'ACCOUNTS',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_PHS_ACCOUNTS_GENERICS' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_phs_audit (
  CUST_ACCT_ID STRING COMMENT 'CUST_ACCT_ID',
  CUST_ACCT_NAME STRING COMMENT 'CUST_ACCT_NAME',
  ACCT_CLASSIFICATION STRING COMMENT 'ACCT_CLASSIFICATION',
  STATUS STRING COMMENT 'STATUS',
  PHS_340B_ID STRING COMMENT 'PHS_340B_ID',
  CUST_CHN_ID STRING COMMENT 'CUST_CHN_ID',
  CHAIN_NAM STRING COMMENT 'CHAIN_NAM',
  NATIONAL_GRP_CD STRING COMMENT 'NATIONAL_GRP_CD',
  NATIONAL_GRP_NAME STRING COMMENT 'NATIONAL_GRP_NAME',
  NATIONAL_SUBGRP_CD STRING COMMENT 'NATIONAL_SUBGRP_CD',
  NATIONAL_SUBGRP_NAME STRING COMMENT 'NATIONAL_SUBGRP_NAME',
  REGION_CD STRING COMMENT 'REGION_CD',
  REGION_NAME STRING COMMENT 'REGION_NAME',
  BUS_TYP_CD STRING COMMENT 'BUS_TYP_CD',
  DELIVERY_DOC STRING COMMENT 'DELIVERY_DOC',
  DIST_CHANNEL BIGINT COMMENT 'DIST_CHANNEL',
  HOME_DC_ID BIGINT COMMENT 'HOME_DC_ID',
  DC_NAME STRING COMMENT 'DC_NAME',
  SALES_ADMIN STRING COMMENT 'SALES_ADMIN',
  MHS_SALES_REP STRING COMMENT 'MHS_SALES_REP',
  SALES_REP STRING COMMENT 'SALES_REP',
  PHS_340B_ID_NOSUFFIX STRING COMMENT 'PHS_340B_ID_NOSUFFIX',
  CE_CITY STRING COMMENT 'CE_CITY',
  CE_STATE STRING COMMENT 'CE_STATE',
  DEA_FAMILY STRING COMMENT 'DEA_FAMILY',
  UPDATE_SAP DATE COMMENT 'UPDATE_SAP',
  COVERED_ENTITY_NAME STRING COMMENT 'COVERED_ENTITY_NAME',
  COVERED_ENTITY_PRIMARY STRING COMMENT 'COVERED_ENTITY_PRIMARY',
  CONTRACT_PHARMACY_NAME STRING COMMENT 'CONTRACT_PHARMACY_NAME',
  CONTRACT_PHARMACY_PRIMARY STRING COMMENT 'CONTRACT_PHARMACY_PRIMARY',
  CONTRACT_PHARMACY_RETAIL STRING COMMENT 'CONTRACT_PHARMACY_RETAIL',
  DSCSA_RECEIVED STRING COMMENT 'DSCSA_RECEIVED',
  UPDATE_TRACKER STRING COMMENT 'UPDATE_TRACKER',
  PVP_MEMBER_NAME STRING COMMENT 'PVP_MEMBER_NAME',
  PVP_PARTICIPANT_ID BIGINT COMMENT 'PVP_PARTICIPANT_ID',
  PVP_PARTICIPATION_FLAG STRING COMMENT 'PVP_PARTICIPATION_FLAG',
  PVP_ELIGIBILITY_DATE DATE COMMENT 'PVP_ELIGIBILITY_DATE',
  PVP_EXPIRATION_DATE DATE COMMENT 'PVP_EXPIRATION_DATE',
  HRSA_START_DATE DATE COMMENT 'HRSA_START_DATE',
  HRSA_TERM_DATE DATE COMMENT 'HRSA_TERM_DATE',
  ACTIVATION_DATE DATE COMMENT 'ACTIVATION_DATE',
  LEADS_PHS STRING COMMENT 'LEADS_PHS',
  LEADS_WAC STRING COMMENT 'LEADS_WAC',
  MNC STRING COMMENT 'MNC',
  ACCT_NAME_A34 STRING COMMENT 'ACCT_NAME_A34',
  ACCT_NAME_C34 STRING COMMENT 'ACCT_NAME_C34',
  ACCT_NAME_PHS STRING COMMENT 'ACCT_NAME_PHS',
  ENTITY_TYPE STRING COMMENT 'ENTITY_TYPE',
  ENTITY_TYPE_NAME STRING COMMENT 'ENTITY_TYPE_NAME',
  AUDIT_GPO STRING COMMENT 'AUDIT_GPO',
  AUDIT_GROUP_NAME STRING COMMENT 'AUDIT_GROUP_NAME',
  AUDIT_COMMENTS STRING COMMENT 'AUDIT_COMMENTS',
  AUDIT_STATUS STRING COMMENT 'AUDIT_STATUS',
  TOTAL_SALES DOUBLE COMMENT 'TOTAL_SALES',
  MPB_EXTENDED STRING COMMENT 'MPB_EXTENDED',
  AGREEMENT STRING COMMENT 'AGREEMENT',
  AGREEMENT_EXPIRATION STRING COMMENT 'AGREEMENT_EXPIRATION',
  PAYMENT_TERM STRING COMMENT 'PAYMENT_TERM',
  RETURNS_MATRIX STRING COMMENT 'RETURNS_MATRIX',
  CAN_NAM STRING COMMENT 'CAN_NAM',
  COMMENTS STRING COMMENT 'COMMENTS',
  RX_COGS DOUBLE COMMENT 'RX_COGS',
  OTC_COGS DOUBLE COMMENT 'OTC_COGS',
  ADDR_DELIVERY STRING COMMENT 'ADDR_DELIVERY',
  ROUTE STRING COMMENT 'ROUTE',
  STOP STRING COMMENT 'STOP',
  ADDR_INVOICE STRING COMMENT 'ADDR_INVOICE',
  DEA_NUM STRING COMMENT 'DEA_NUM',
  RX_BILL_PLAN STRING COMMENT 'RX_BILL_PLAN',
  SALES_LSTQTR STRING COMMENT 'SALES_LSTQTR',
  SALES_LSTMTH STRING COMMENT 'SALES_LSTMTH',
  SALES_CURMTH STRING COMMENT 'SALES_CURMTH',
  GPO_ID STRING COMMENT 'GPO_ID',
  GPO_ACCT STRING COMMENT 'GPO_ACCT',
  PVP_CODE STRING COMMENT 'PVP_CODE',
  PVP_CODING STRING COMMENT 'PVP_CODING',
  THIRD_PARTY_VENDOR STRING COMMENT 'THIRD_PARTY_VENDOR',
  ZX_BLOCK STRING COMMENT 'ZX_BLOCK',
  OPENED_FOR_RETURNS STRING COMMENT 'OPENED_FOR_RETURNS',
  ACM_NAME STRING COMMENT 'ACM_NAME',
  MAIN_LEAD STRING COMMENT 'MAIN_LEAD',
  UPDATE_ACTIVESTATUS DATE COMMENT 'UPDATE_ACTIVESTATUS',
  UPDATE_340BID DATE COMMENT 'UPDATE_340BID',
  FIRST_ORDER DATE COMMENT 'FIRST_ORDER',
  LAST_ORDER DATE COMMENT 'LAST_ORDER',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_PHS_AUDIT'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_pvp_report (
PVP_PARTICIPANT_ID BIGINT,
PVP_PARTICIPATION_FLAG BOOLEAN,
COMMITTED_LOP_LOCS STRING,
PVP_ENTITY_TYPE STRING,
PVP_340B_ID STRING,
PVP_PARENT_340B_ID STRING,
HRSA_TERM_CODE STRING,
HRSA_TERM_DATE INTEGER,
PVP_MEMBER_NAME STRING,
PVP_ADDRESS_HEADER STRING,
PVP_ADDRESS_LINE_1 STRING,
PVP_ADDRESS_LINE_2 STRING,
PVP_CITY STRING,
PVP_STATE STRING,
PVP_ZIP_CODE BIGINT,
PVP_ZIP_CODE_EXT BIGINT,
HRSA_MEMBER_DATE INTEGER,
PVP_EFFECTIVE_DATE INTEGER,
PVP_EXPIRATION_DATE INTEGER,
HIN_NUMBER STRING,
COVERED_ENTITY_DEA_NUMBER STRING,
PVP_BILLING_PARTICIPANT_NAME STRING,
PVP_BILLING_ADDRESS1 STRING,
PVP_BILLING_ADDRESS2 STRING,
PVP_BILLING_CITY STRING,
PVP_BILLING_STATE STRING,
PVP_BILLING_ZIP BIGINT,
PVP_BILLING_ZIP2 BIGINT,
PVP_SHIPPING_PARTICIPANT_NAME STRING,
PVP_SHIPPING_ADDRESS1 STRING,
PVP_SHIPPING_ADDRESS2 STRING,
PVP_SHIPPING_CITY STRING,
PVP_SHIPPING_STATE STRING,
PVP_SHIPPING_ZIP STRING,
PVP_SHIPPING_ZIP2 STRING,
PRIME_VENDOR_CONTACT1_NAME STRING,
PRIME_VENDOR_CONTACT1_EMAIL STRING,
PRIME_VENDOR_CONTACT1_TITLE STRING,
PRIME_VENDOR_CONTACT1_TELEPHONE_NUMBER STRING,
PRIME_VENDOR_CONTACT2_NAME STRING,
PRIME_VENDOR_CONTACT2_EMAIL STRING,
PRIME_VENDOR_CONTACT2_TITLE STRING,
PRIME_VENDOR_CONTACT2_TELEPHONE STRING,
PRIME_VENDOR_CONTACT3_NAME STRING,
PRIME_VENDOR_CONTACT3_EMAIL STRING,
PRIME_VENDOR_CONTACT3_TITLE STRING,
PRIME_VENDOR_CONTACT3_TELEPHONE STRING,
ENTITY_MEDICAID_NUMBER STRING,
ENTITY_GRANT_NUMBER STRING,
ALT_METHODS BOOLEAN,
PVP_SHIPPING_HIN STRING,
ORIGINAL_PVP_PARTICIPANT_ID STRING,
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_PVP_REPORT' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_ta_phmmmd_dm_vstx_cust (
KUNNR_CUST string, 
CUST_ACCT_ID string,
XFD_KU_CK_DGT decimal(38,18),
XFD_KU_BILLING_BLK string,
XFD_KU_AUTH string,
XFD_KU_TELEBOX string,
XFD_KU_INDST_CD_4 string,
XFD_KU_INDST_CD_3 string,
XFD_KU_PBC_REQR string,
XFD_KU_DEA_WARN decimal(38,18),
XFD_KU_DEA_FAMILY string,
XFD_KU_ORIG_DC string,
XFD_KU_CO_IND string,
XFD_KU_ASN_HIER string,
XFD_KU_ASN_FLG_IND string,
XFD_KU_COND_GRP_1 string,
XFD_KU_VAT_REG_NO string,
XFD_KU_PSTNG_BLK string,
XFD_KU_ORD_BLK string,
XFD_KU_LOC_NO_2 decimal(38,18),
XFD_KU_LOC_NO_1 decimal(38,18),
XFD_KU_INDST string,
XFD_KU_DEL_BLK string,
XFD_KU_340B_ID string,
XFD_KU_REGLTORY_DC string,
XFD_KU_PREPAY_ID string,
XFD_KU_PLNOGRM_SIGNAGE string,
XFD_KU_PLNOGRM_CD string,
XFD_KU_INV_REF_CK string,
XFD_KU_PED_REF_TYP string,
XFD_KU_PED_ENA string,
XFD_KU_RTN_PRTOUT string,
MCK_KU_VRITE string,
XFD_KU_DLVRY_BLK string,
XFD_KU_CUST_CLS string,
XFD_KU_ACCT_GRP string,
XFD_KU_CORP_GRP string,
XFD_KU_ATRB_10 string,
XFD_KU_ATRB_1 string,
XFD_KU_ATRB_2 string,
XFD_KU_ATRB_7 string,
XFD_KU_ATRB_3 string,
XFD_KU_INDST_CD_2 string,
XFD_KU_TRNSPORTZON string,
XFD_KU_INDST_CD_1 string,
XFD_KU_EXPR_STN string,
MCK_KU_TERM_RSN string,
MCK_KU_RPTTYP string,
MCK_KU_INVDISCD string,
MCK_KU_SHPLBLTYP string,
MCK_KU_VNDR_TYP string,
MCK_KU_ACTV_DT timestamp,
MCK_KU_INV_DT_EXCL string,
MCK_KU_EQUI_SERV_DT timestamp,
MCK_KU_ITEM_STK_CONF string,
MCK_KU_CONF_TYP string,
MCK_KU_LATEPMT decimal(38,18),
MCK_KU_RX_NONRSLTX decimal(38,18),
MCK_KU_OTC_RSLTX decimal(38,18),
MCK_KU_OTC_NONRSLTX decimal(38,18),
MCK_KU_EXITDATA string,
MCK_KU_HIN_LOC string,
MCK_KU_HIN_DEPT string,
MCK_KU_DOC_NUM string,
MCK_KU_SITEID string,
MCK_KU_EXCLSERVCHRG string,
MCK_KU_PRI_SITEID string,
MCK_KU_DUNLTR string,
MCK_KU_STMT_FREQ string,
MCK_KU_CONSOL_TYP string,
MCK_KU_OSDTXT string,
MCK_KU_CORPCONS string,
MCK_KU_LIMORD decimal(38,18),
MCK_KU_CRD_LIMTOT decimal(38,18),
MCK_KU_TOTESPLIT string,
MCK_KU_DEA_ELIG string,
MCK_KU_WEB_VRITE string,
MCK_KU_ORD_FLTR_CD string,
MCK_KU_ITEM_FLTR_CD string,
MCK_KU_RX_SUB_ADJ2 string,
MCK_KU_RX_SUB_ADJ1 string,
MCK_KU_ERLY_RTE string,
MCK_KU_RX_SUB_ADJ0 string,
MCK_KU_EOE_LAST_QTY string,
MCK_KU_ALT_SRC string,
MCK_KU_SAM string,
MCK_KU_MULTI_SRC string,
MCK_KU_INIT_LOAD timestamp,
MCK_KU_PROMO_END_RSN string,
XFD_KU_TELETEX_1 string,
MCK_KU_MKUP1 decimal(38,18),
MCK_KU_ESTABBY string,
MCK_KU_PRC_TYP string,
MCK_KU_RPTLEADGRP string,
MCK_KU_RPTLEADNAM string,
MCK_KU_MEMNETWKCD string,
MCK_KU_RX_SUB_ADJ5 string,
MCK_KU_MEDST string,
MCK_KU_RX_SUB_ADJ3 string,
MCK_KU_OTCUPD string,
MCK_KU_BIWK string,
MCK_KU_LBLSTK string,
MCK_KU_STORELBL string,
MCK_KU_COST_CD0 string,
MCK_KU_COST_CD6 string,
MCK_KU_COST_CD9 string,
MCK_KU_COST_CD7 string,
XFD_KU_VNDR string,
MCK_KU_COST_CD8 string,
MCK_KU_STAT_CUST_FEP string,
MCK_KU_OTC_SUB_ADJ2 string,
MCK_KU_RX_SUB_ADJ6 string,
MCK_KU_SECR_TCH_TONE string,
MCK_KU_RX_SUB_ADJ7 string,
MCK_KU_CRREQ_CUST string,
MCK_KU_RX_SUB_ADJ8 string,
MCK_KU_PVT_LBL string,
MCK_KU_RX_SUB_ADJ9 string,
MCK_KU_OTC_RTL_DT_CD string,
MCK_KU_RX_SUB_CHAR0 string,
MCK_KU_RX_RTL_DT_CD string,
MCK_KU_RX_SUB_CHAR1 string,
MCK_KU_OTC_RTL_PLN_PCT1 decimal(38,18),
MCK_KU_RX_SUB_CHAR2 string,
MCK_KU_RX_RTL_PLN_PCT1 decimal(38,18),
MCK_KU_RX_SUB_CHAR3 string,
MCK_KU_ALPHA_SORT string,
MCK_KU_RX_SUB_CHAR4 string,
MCK_KU_LIMTOT decimal(38,18),
MCK_KU_RX_SUB_CHAR5 string,
MCK_KU_RX_SUB_CHAR6 string,
MCK_KU_RX_SUB_CHAR7 string,
MCK_KU_COST_CD1 string,
MCK_KU_RX_SUB_CHAR8 string,
MCK_KU_COST_CD2 string,
MCK_KU_RX_SUB_CHAR9 string,
MCK_KU_COST_CD3 string,
MCK_KU_OTC_SUB_ADJ0 string,
MCK_KU_COST_CD4 string,
MCK_KU_PRC_OVR_GRP string,
MCK_KU_PRC_OVR_MTH string,
MCK_KU_PRC_OVR_PCT1 decimal(38,18),
MCK_KU_VKORG string,
MCK_KU_OTC_SUB_ADJ1 string,
XFD_KU_ATRB_8_1 string,
MCK_KU_COST_CD5 string,
MCK_KU_RX_RTL_FMT_CD string,
MCK_KU_OTC_SUB_CHAR0 string,
MCK_KU_OTC_SUB_CHAR1 string,
MCK_KU_RX_SUB_ADJ4 string,
MCK_KU_OTC_SUB_CHAR2 string,
MCK_KU_SPART string,
MCK_KU_SUB_ADJ6 string,
MCK_KU_OTC_SUB_ADJ9 string,
MCK_KU_SUB_CHAR string,
MCK_KU_CUST_PRC_PLN_SPCL_P string,
MCK_KU_CUST_PRC_PLN_SPCL string,
XFD_KU_ALTPAYER string,
MCK_KU_CR_STAT string,
XFD_KU_ATRB_5_1 string,
MCK_KU_PROFL_ITEM string,
XFD_KU_ATRB_4_1 string,
MCK_KU_DEPT_LGTH decimal(38,18),
XFD_KU_ATRB_6_1 string,
MCK_KU_DEPT_FMT string,
MCK_KU_SUB_FLD decimal(38,18),
MCK_KU_ITEM_LGTH decimal(38,18),
MCK_KU_SUB_ADJ string,
MCK_KU_ITEM_FMT string,
MCK_KU_RGN_LGTH decimal(38,18),
MCK_KU_OTC_SUB_ADJ7 string,
MCK_KU_RGN_FMT string,
MCK_KU_OTC_SUB_ADJ8 string,
MCK_KU_ITEM_INPUT1 string,
MCK_KU_OTC_SUB_CHAR4 string,
MCK_KU_OTC_SUB_ADJ6 string,
MCK_KU_OTC_SUB_CHAR3 string,
MCK_KU_OTC_SUB_ADJ5 string,
MCK_KU_CR_MSG string,
MCK_KU_OTC_SUB_ADJ4 string,
MCK_KU_OTC_SUB_CHAR5 string,
MCK_KU_OTC_SUB_ADJ3 string,
MCK_KU_DEPT_INV1 string,
MCK_KU_PRC_STKR_IND string,
MCK_KU_DEPT_INV2 string,
MCK_KU_ITEM_INPUT2 string,
MCK_KU_CUST_INPUT1 string,
MCK_KU_CUST_INPUT2 string,
MCK_KU_ITEM_INV1 string,
MCK_KU_ITEM_INV2 string,
MCK_KU_MCK_DEPT string,
MCK_KU_CUST_DEPT string,
MCK_KU_PREPYMT decimal(38,18),
MCK_KU_CUST_LGTH decimal(38,18),
MCK_KU_DSTRCT_LGTH decimal(38,18),
MCK_KU_CUST_FMT string,
MCK_KU_DSTRCT_FMT string,
MCK_KU_PROMOEND timestamp,
MCK_KU_RPT_GRP_SLS_TAX string,
MCK_KU_SUB_ADJ5 string,
MCK_KU_CNFRM_SEQ string,
MCK_KU_SUB_ADJ0 string,
MCK_KU_CNFRM_RPT string,
MCK_KU_SUB_ADJ8 string,
MCK_KU_SUB_ADJ7 string,
MCK_KU_SUB_ADJ1 string,
MCK_KU_SUB_ADJ4 string,
MCK_KU_SUB_ADJ3 string,
MCK_KU_SUB_ADJ2 string,
MCK_KU_SPCLS string,
MCK_KU_OTC_SUB_CHAR8 string,
MCK_KU_OTC_SUB_CHAR9 string,
MCK_KU_CR_TERMS string,
MCK_KU_DS_XCPT_RX decimal(38,18),
MCK_KU_CUST_DEPT_DESC string,
MCK_KU_DS_XCPT_OTC decimal(38,18),
MCK_KU_MKUP decimal(38,18),
MCK_KU_SVC_PROG_TYP string,
MCK_KU_PRC_OVR_PCT decimal(38,18),
MCK_KU_PICK_CONSOL string,
MCK_KU_ADDBILL_THRESH string,
MCK_KU_PROMO_MGR_RTL string,
MCK_KU_PROCESS_GRP_CD string,
MCK_KU_WRKLD_BAL_EXCL string,
MCK_KU_OTC_RTL_FMT_CD string,
MCK_KU_FMT_PRC_LBL string,
MCK_KU_DLOC_ST_CD string,
MCK_KU_PREFD_CUST string,
MCK_KU_DLOC_REGN string,
MCK_KU_DS_ELIG string,
MCK_KU_RTL_RX_LBL_CONST2 string,
MCK_KU_INV_SPLIT_ORD string,
MCK_KU_DLOC_AREA string,
MCK_KU_OTC_SUB_CHAR6 string,
MCK_KU_DLOC_ABBR string,
MCK_KU_OTC_SUB_CHAR7 string,
MCK_KU_ST_PHARM string,
MCK_KU_HIN_BASE string,
MCK_KU_NCPDP string,
MCK_KU_RTL_RX_LBL_CONST1 string,
MCK_KU_DEA_SEC_EXPIR timestamp,
MCK_KU_PRI_ACCT string,
MCK_KU_PRICING_LEAD string,
MCK_KU_RETL_LEAD string,
MCK_KU_ST_PHARM_EXPIR timestamp,
MCK_KU_MKTG_OPTN string,
MCK_KU_XREF_LEAD string,
MCK_KU_RPT_LEAD string,
MCK_KU_SHIP_FEE_CD_REG string,
MCK_KU_SHIP_FEE_CD_OVRNITE string,
MCK_KU_PO_REQR string,
MCK_KU_OTC_FEE_CD string,
MCK_KU_OTC_RTL_PLN_PCT decimal(38,18),
MCK_KU_RX_FEE_CD string,
MCK_KU_RX_RTL_PLN_PCT decimal(38,18),
XFD_KU_KATR4 string,
XFD_KU_KATR3 string,
MCK_KU_ALIAS string,
XFD_KU_KATR2 string,
MCK_KU_PROMOIDS string,
MCK_KU_CALL_FREQ decimal(38,18),
MCK_KU_OTCDSMKUP decimal(38,18),
MCK_KU_EDI_BILLTYP string,
MCK_KU_RXDSMKUP decimal(38,18),
MCK_KU_NPI string,
MCK_KU_OTC_RTL_LBL_CONST2 string,
MCK_KU_OTC_PROMO_BILL_PLN string,
MCK_KU_SUB_CHAR6 string,
MCK_KU_RX_PROMO_BILL_PLN string,
MCK_KU_SUB_CHAR5 string,
MCK_KU_SHIP_METH string,
MCK_KU_SUB_CHAR4 string,
MCK_KU_RXPROMOMKUP decimal(38,18),
MCK_KU_SUB_CHAR3 string,
MCK_KU_OTC_RTL_LBL_CONST1 string,
MCK_KU_SUB_CHAR2 string,
MCK_KU_PRRTY string,
MCK_KU_SUB_CHAR1 string,
MCK_KU_SUB_CHAR9 string,
MCK_KU_SUB_CHAR0 string,
MCK_KU_SUB_CHAR8 string,
MCK_KU_DEA_SCNDRY string,
MCK_KU_OTCPROMOMKUP decimal(38,18),
MCK_KU_SUB_ADJ9 string,
MCK_KU_OTCMKUP decimal(38,18),
MCK_KU_RXMKUP decimal(38,18),
MCK_KU_OUTPUT_TYP string,
MCK_KU_EQUI_SER string,
MCK_KU_RQRMT decimal(38,18),
MCK_KU_EQUI_MDL string,
MCK_KU_SND_CNCL string,
MCK_KU_DELY_TAX_LOCN string,
MCK_KU_XCLD string,
MCK_KU_TRGT_FMT string,
MCK_KU_MANL string,
MCK_KU_TRGT_ID string,
MCK_KU_SLPS_TER_RSN string,
MCK_KU_TRGT_SYS string,
MCK_KU_SLPS_RX_OVR_IND string,
MCK_KU_SUB_CHAR7 string,
MCK_KU_CRD_RVW_DT string,
MCK_KU_DLOC_DCTYP string,
MCK_KU_DLOC_ALLOC_STAT string,
MCK_KU_CHNL_TYP string,
MCK_KU_DLOC_MRG_STAT string,
MCK_KU_GPO string,
MCK_KU_DLOC_FILENO string,
MCK_KU_SLPS_OTC_OVR_IND string,
MCK_KU_DLOC_CYCLNUM string,
MCK_KU_SLPS_CP string,
MCK_KU_RPTLEAD string,
MCK_KU_SLPS_MIN_QTY string,
XFD_KU_TRAIN_STN string,
MCK_KU_START_DT timestamp,
MCK_KU_DEA_EXPIR timestamp,
MCK_KU_VAR_PRC_REP string,
MCK_KU_CRD_LIMTOT_1 decimal(38,18),
MCK_KU_EFF_ENDDT timestamp,
MCK_KU_SLPS_L_STK string,
MCK_KU_ST_CS_LCNS string,
MCK_KU_SLPS_SS_CD string,
MCK_KU_ST_CS_LCNS_EXPIR timestamp,
MCK_KU_CNTRC_CBREFNUM string,
XFD_KU_CSOS_CK_ACTV string,
MCK_KU_CNTRC_VNDRNAM string,
MCK_KU_SLPS_LAYOUT string,
MCK_KU_CSMK_CHG decimal(38,18),
MCK_KU_AREARGN string,
MCK_KU_LCNS_TYP string,
MCK_KU_SLPS_L_TYP string,
MCK_KU_PRTNR string,
MCK_KU_SLPS_SS_OVR_IND string,
MCK_KU_CRD_LIMTOT_2 decimal(38,18),
MCK_KU_LCNS_TYP_DES string,
MCK_KU_DIST_CUST string,
MCK_KU_CUST_CR_RT string,
MCK_KU_E222_DEA_ASSN string,
MCK_KU_RAM string,
MCK_KU_DEA_CLS string,
MCK_KU_ACCT_STAT string,
MCK_KU_CUST_DUNS_RT string,
MCK_KU_CNTRC_COMM string,
MCK_KU_COLL_AGCY string,
MCK_KU_CNTRC_CDKEY string,
MCK_KU_CR_MGR string,
MCK_KU_RX_RSLTX decimal(38,18),
MCK_KU_CR_LIM_RVW_NEXT_YM decimal(38,18),
MCK_KU_ORD_CONFRM_PH decimal(38,18),
MCK_KU_RASR string,
MCK_KU_PROMOSTART timestamp,
MCK_KU_OPRGRP string,
MCK_KU_BNS_GOODS_QUAL string,
MCK_KU_CSMK_CD string,
MCK_KU_RXOTC_IND string,
MCK_KU_VAT_REG_NO_EXPIR timestamp,
MCK_KU_SLPS_RX_IND string,
MCK_KU_PCT_REBT decimal(38,18),
MCK_KU_SLPS_OTC_IND string,
MCK_KU_EDI_CORR_ID string,
MCK_KU_RPAR_CUST string,
MCK_KU_VNDR string,
MCK_KU_WHSLR string,
MCK_KU_CR_AUTH_TYP string,
MCK_KU_FUTR_OF_SCRPT string,
MCK_KU_CHN string,
MCK_KU_MRKT_CMPGN string,
MCK_KU_CHN_DUMMY string,
MCK_KU_NATL_GRP_DUMMY string,
MCK_KU_SUB_GRP_DUMMY string,
MCK_KU_CUST_RGN_DUMMY string,
MCK_KU_CUST_DSTRCT_DUMMY string,
MCK_KU_CHN_DUMMY_DESC string,
MCK_KU_NAT_GRP_DUMMY_DESC string,
MCK_KU_SUB_GRP_DUMMY_DESC string,
MCK_KU_CUST_RGN_DUMMY_DESC string,
MCK_KU_CUST_DIST_DUMMY_DESC string,
MCK_KU_CR_AUTH_REQ_FLG timestamp,
MCK_KU_CUST_LIST_NUM string,
MCK_KU_CUST_LIST_RQSTR string,
MCK_KU_CASH_DSCNT_FLG string,
MCK_KU_INTEREST_IND_TYP string,
MCK_KU_CR_MGR_USR_NAM string,
MCK_KU_CR_TERMS_PLASMA string,
MCK_KU_CASH_DSCNT_FLG_PLSM string,
MCK_KU_LATEPMT_PLASMA decimal(38,18),
MCK_KU_INVDISCD_PLASMA string,
MCK_KU_FORM_REQ_TYP string,
MCK_KU_EXPLANATION string,
MCK_KU_RX_HIER_OPT string,
MCK_KU_OTC_HIER_OPT string,
MCK_KU_COID string,
MCK_KU_CORRID string,
MCK_KU_EDIDOCTYP string,
MCK_KU_EDIPICKTYP string,
MCK_KU_GRPID string,
MCK_KU_PROMOID string,
MCK_KU_PROMOID_1 string,
MCK_KU_RMDY_REQ_NUM string,
MCK_KU_RMDY_RQSTR string,
MCK_KU_INVCPY_CTRLD decimal(38,18),
MCK_KU_CR_CUST string,
MCK_KU_EXT_ORDERING string,
MCK_KU_LYNX_PARENT_ACCOUNT string,
MCK_KU_DSCSA string,
MCK_KU_ACCT_CLAS string,
MCK_KU_ACCT_CLAS_DESC string,
MCK_KU_GPOS string,
MCK_KU_GPOS_DESC string,
MCK_KU_GPO_ACCT string,
MCK_KU_GOVT_CONTRACT_IND string,
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_TA_PHMMMD_DM_VSTX_CUST'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_tpv (
  ID STRING COMMENT 'ID',
  VENDOR_NAME STRING COMMENT 'VENDOR_NAME',
  TPV STRING COMMENT 'TPV',
  ACCOUNT_MANAGER STRING COMMENT 'ACCOUNT_MANAGER',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_TPV'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_apexus_code_key (
    LEAD_NO BIGINT,
    CODE_KEY BIGINT,
    ORG_ID_SEQ STRING,
    CONTRACT_NAME STRING,
    VENDOR_NO BIGINT,
    VENDOR_NAME STRING,
    MATERIAL BIGINT,
    EAN_UPC STRING,
    MATERIAL_DESCRIPTION STRING,
    ORIGINAL_VALID_FROM INTEGER,
    ORIGINAL_VALID_TO INTEGER,
    BID_PRICE DOUBLE,
    VARIANCE STRING,
    WAC DOUBLE,
    NO_CHARGEBACK_INDICATOR STRING,
    GPO_CHBK_REF_NO STRING,
    GENERIC_FLAG STRING,
    ITEM_STATUS STRING,
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_APEXUS_CODE_KEY'  
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.T_APEXUS_PHS_ACCT_BY_LEAD (
    LEAD_NO BIGINT,
    CODE_KEY BIGINT,
    ORG_ID_SEQ STRING,
    CONTRACT_NAME STRING,
    VENDOR_NO BIGINT,
    VENDOR_NAME STRING,
    MATERIAL BIGINT,
    EAN_UPC STRING,
    MATERIAL_DESCRIPTION STRING,
    ORIGINAL_VALID_FROM INTEGER,
    ORIGINAL_VALID_TO INTEGER,
    BID_PRICE DOUBLE,
    VARIANCE STRING,
    WAC DOUBLE,
    NO_CHARGEBACK_INDICATOR STRING,
    GPO_CHBK_REF_NO STRING,
    GENERIC_FLAG STRING,
    ITEM_STATUS STRING,
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_APEXUS_PHS_ACCT_BY_LEAD' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.T_APEXUS_WAC_ACCT_BY_LEAD (
    LEAD_NO BIGINT,
    CODE_KEY STRING,
    ORG_ID_SEQ STRING,
    CONTRACT_NAME STRING,
    VENDOR_NO BIGINT,
    VENDOR_NAME STRING,
    MATERIAL BIGINT,
    EAN_UPC STRING,
    MATERIAL_DESCRIPTION STRING,
    ORIGINAL_VALID_FROM INTEGER,
    ORIGINAL_VALID_TO INTEGER,
    BID_PRICE DOUBLE,
    VARIANCE DOUBLE,
    WAC DOUBLE,
    NO_CHARGEBACK_INDICATOR STRING,
    GPO_CHBK_REF_NO STRING,
    GENERIC_FLAG STRING,
    ITEM_STATUS STRING,
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_APEXUS_WAC_ACCT_BY_LEAD' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);



-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_apexusfile (
  ID STRING COMMENT 'ID',
  APEXUS_340B_ID STRING COMMENT 'APEXUS_340B_ID',
  ENTITY_NAME STRING COMMENT 'ENTITY_NAME',
  SHIP_TO_ACCT_NAME STRING COMMENT 'SHIP_TO_ACCT_NAME',
  SHIP_TO_ACCT_NO BIGINT COMMENT 'SHIP_TO_ACCT_NO',
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_APEXUSFILE' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.T_PHS_MEMBERSHIPROSTER_WAC (
CUST_ACCT_ID STRING,
CUST_NAME STRING,
340B_ID STRING,
PVP_PARTICIPANT_ID STRING,
PVP_PARTICIPATION_FLAG STRING,
PVP_MEMBER_NAME STRING,
PVP_EFFECTIVE_DATE STRING,
PVP_EXPIRATION_DATE STRING,
STORE_NUM STRING,
DEA_FAMILY STRING,
MARKETING_CAMPAIGN STRING,
HOME_DC_ID STRING,
DEA_NUM STRING,
HIN_BASE_CD STRING,
HIN_DEPT_CD STRING,
HIN_LOCATION_CD STRING,
HIN_NUM STRING,
ATTENTION_NAME_DELY STRING,
ADDR_LINE_1_DELY STRING,
ADDR_LINE_2_DELY STRING,
CITY_NAME_DELY STRING,
STATE_CD_DELY STRING,
ZIP_CD_DELY STRING,
ATTENTION_NAME_INV STRING,
ADDR_LINE_1_INV STRING,
ADDR_LINE_2_INV STRING,
CITY_NAME_INV STRING,
STATE_CD_INV STRING,
ZIP_CD_INV STRING,
CUST_CHAIN_ID STRING,
CUST_CHAIN_NAME STRING,
NATIONAL_GROUP_CD STRING,
NATIONAL_GROUP_NAME STRING,
NATIONAL_SUB_GROUP_CD STRING,
NATIONAL_SUB_GROUP_NAME STRING,
REGION_NUM STRING,
REGION_NAME STRING,
DISTRICT_NUM STRING,
DISTRICT_NAME STRING,
RX_BILL_PLAN_CD STRING,
BUSINESS_TYPE_CD STRING,
DISTRIBUTION_CHANNEL STRING,
SALES_TERRITORY_ID STRING,
PRIMARY_CUST_ID STRING,
3RD_PARTY_VENDOR STRING,
SECONDARY_VENDOR STRING,
OTHER_VENDORS STRING,
ACCOUNT_CLASSIFICATION STRING,
ACCOUNT_CLASSIFICATION_DESCRIPTION STRING,
_rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_PHS_MEMBERSHIPROSTER_WAC' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.t_iw_cust_acct (
CUST_ACCT_ID string,
CUST_NUM string,
CUST_BUS_TYP_CD string,
SLS_TERR_ID string,
PRI_FILL_DC_ID string,
NATL_ACCT_ID string,
CUST_ACCT_NAM string,
HIN_NUM string,
PRI_ACCT_IND  string,
DLVRY_RTE_NUM string,
DLVRY_RTE_STOP_NUM string,
VRITE_BUS_TYP_CD string,
VRITE_REBT_IND string,
ACCT_DLVRY_ADDR string,
ACCT_DLVRY_CTY_NAM string,
ACCT_DLVRY_ST_ABRV string,
ACCT_DLVRY_ZIP string,
ACCT_DLVRY_ZIP_SFX string,
HOME_DC_ID string,
HOME_DC_DSCR string,
SLSPRSN_ID string,
NATL_ACCT_DSCR string,
PRI_FILL_DC_DSCR string,
NABP_NUM string,
DEA_NUM string,
VRITE_CUST_IND string,
CUST_CHN_ID string,
CUST_STOR_NUM string,
ACCT_DLVRY_AREA_CD string,
ACCT_DLVRY_PH_NUM string,
ACTIVE_CUST_IND string,
XTRCT_DT string,
CR_STAT_CD string,
DEA_NUM_EXPIR_DT string,
ST_PHARM_LCNS_NUM string,
MDCD_ST_ABRV string,
DLVRY_ATTN_NAM string,
CR_LMT_DLLR_AMT integer,
PMT_TRMS_CD string,
CUR_DUE_DLLR_AMT decimal(38,18),
TOT_DUE_DLLR_AMT decimal(38,18),
MS_SCHM_ID string,
CUST_RGN_NUM string,
CUST_DSTRCT_NUM string,
CUST_CMAX_IND string,
CUST_OMNI_IND string,
CUST_SEL_GNRC_IND string,
MCK_ACCT_VNDR_CD string,
NATL_GRP_CD string,
NATL_SUB_GRP_CD string,
ACCT_SVC_ELIG_BEG_DT timestamp,
ACCT_SVC_ELIG_END_DT timestamp,
ACCT_CHN_ID string,
ALT_SRC_ID string,
CUST_ACCT_HIN_BASE_CD string,
CUST_ACCT_HIN_LOC_CD string,
CUST_ACCT_HIN_DEPT_CD string,
ORDFLTR_CUSTGRP_ID string,
ORDR_ITEM_FLTR_CD string,
DLVRY_DOC_IND string,
CUST_ASGN_MCK_IND string,
INVC_FMT_CD string,
INVC_SUM_TYP_CD string,
MCK_CO_CD string,
CUST_LOC_ID string,
ACCT_LOC_ID string,
ACCT_STOR_NUM string,
RETL_ACCT_MNGR_ID string,
RETL_ACCT_SVC_REP_ID string,
NPI_NUM string,
SITE_ID string,
PRI_SITE_IND string,
SRC_ID_MULT string,
CUST_TYPE_BUS string,
ITEM_CNTRL1 string,
ITEM_CNTRL2 string,
ITEM_CNTRL3 string,
ITEM_CNTRL4 string,
ITEM_CNTRL5 string,
ITEM_CNTRL6 string,
ITEM_CNTRL7 string,
ITEM_CNTRL8 string,
DELY_FEE string,
AR_PPD string,
CUST_SVC_BEG2 string,
CUST_SVC_END3 string,
DEA_CRN_EXP_DT string,
DEA_CHEM_REG_NO string,
NEW_MAIL_NAME string,
FAX_CUST_AREA string,
ADR_CUST_DELY2 string,
ITEM_PVT_LBL string,
FILLER string,
SRC_ID_MULT1 string,
CUST_GRP string,
DEA_NUM_SH string,
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_IW_CUST_ACCT'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS   psas_di_dev.340b_slvr.T_MPB_PHS_WAC_TEMP (
	CUSTOMER STRING,
	COCD STRING,
	DATE DATE,
	NAME_1 STRING,
	NAME_2 STRING,
	STREET STRING,
	CITY STRING,
	RG STRING,
	POSTALCODE STRING,
	340B_CONTRACT_PHARMACY_ACCOUNT STRING,
	340B_ID STRING,
	TYPE_OF_BUSINESS STRING,
	CUSTOMER_CLASSIFICATION STRING,
	CL STRING,
	DELF STRING,
	ORBLK STRING,
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_MPB_PHS_WAC_TEMP'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS  psas_di_dev.340b_slvr.T_TRACKER_TEMP(ID STRING,
PRIMARY_TPV STRING,
ACCT_MANAGER STRING,
TPV_CONTACT STRING,
SECONDARY_TPV STRING,
EXISTING_ACCT_TO_MIRROR STRING,
DATE_VENDOR_REQUESTED STRING,
DATE_SENT_FOR_APPROVAL STRING,
ID_340B STRING,
PVP_ID STRING,
CE_A_MCK_CUST STRING,
COVERED_ENTITY STRING,
CP_A_MCK_CUST STRING,
CONTRACT_PHARMACY_NAME STRING,
CP_STORE STRING,
DSCSA_REQUESTED STRING,
MPB_REQUESTED_W_PACKET STRING,
DEA_FAMILY_OF_EXISTING_ACCT STRING,
DEA_WARNING_OF_EXISTING_ACCT STRING,
HRSA_ELIGIBILITY_DATE STRING,
MCK_DC STRING,
VPGM STRING,
RETAIL_AND_MHS_SA_CONTACT STRING,
FIELD_ACCT_MANAGER STRING,
ACCOUNT STRING,
ACCOUNT_NAME STRING,
DATE_CONTRACTS_CONNECT_ACCESS_REQUESTED STRING,
DATE_EDI_REQUESTED STRING,
ACCOUNT_SET_UP_NOTES STRING,
DATE_CSMP_LOAD_REQUESTED STRING,
DATE_EDI_CREDITS_REQUESTED_WALMART_ONLY STRING,
APEXUS_ID STRING,
CE_ACCOUNT_NUMBER_EXISTING STRING,
CE_ACCOUNT_NAME_EXISTING STRING,
COVERED_ENTITY_DEA STRING,
COVERED_ENTITY_STREET_ADDRESS STRING,
COVERED_ENTITY_CITY STRING,
COVERED_ENTITY_STATE STRING,
COVERED_ENTITY_ZIP_CODE STRING,
COVERED_ENTITY_PHONE_NUMBER STRING,
CP_DEA STRING,
CONTRACT_PHARM_STREET_ADDRESS STRING,
CONTRACT_PHARM_CITY STRING,
CONTRACT_PHARM_STATE STRING,
CONTRACT_PHARM_ZIP_CODE STRING,
CONTRACT_PHARM_PHONE STRING,
CP_COG STRING,
CP_CHAIN STRING,
CP_NATIONAL_GROUP STRING,
CP_SUBGROUP STRING,
CP_REGION STRING,
CP_DISTRICT STRING,
PACKET_SENT_TO_DC STRING,
ITEM_TYPE STRING,
PATH STRING,
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_TRACKER_TEMP'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true);


-- COMMAND ----------

CREATE TABLE IF NOT EXISTS  psas_di_dev.340b_slvr.T_QUARTERLY_AUDIT_DATA(
STATUS STRING,
GPO STRING,
GROUP_NAME STRING,
CHAIN STRING,
ACCT_CHAIN_NAME STRING,
NATIONAL_GROUP_CD STRING,
NATIONAL_GROUP_NAM STRING,
NATIONAL_SUB_GROUP_CD STRING,
NATIONAL_SUB_GROUP_NAME STRING,
REGION_NUM STRING,
REGION_NAME STRING,
DISTRICT_NUM STRING,
DISTRICT_NAME STRING,
DEA_NUM STRING,
DEA_NUM_EXPIRE TIMESTAMP_NTZ(9),
DEA_FAMILY STRING,
CS_LICENSE STRING,
STATE_PHARMACY_LICENSE_NUM STRING,
STATE_PHARMACY_LICENSE_NUM_EXPIRE TIMESTAMP_NTZ(9),
HIM_NUM STRING,
PHS_340B_ID STRING,
PHS_CONTRACTPHARMA STRING,
PHS_IND STRING,
PHS_PVP STRING,
PHS_AGMT_CD STRING,
ACCT_CLASS_DESC STRING,
NCPDP STRING,
NPI STRING,
AUDITED STRING,
AUDIT_STATUS STRING,
COMMENTS STRING,
CUST_ACCT_ID STRING,
CUST_NAME STRING,
HOME_DC_ID STRING,
DC_DESC STRING,
ADDRESS_DELIVERY STRING,
ADDRESS_STATE STRING,
PRIMARY_CUST_ID STRING,
PRIMARY_SECONDARY_ STRING,
ALIAS STRING,
SERVICE_ELIGIBILITY_BEGIN TIMESTAMP_NTZ(9),
SERVICE_ELIGIBILITY_END TIMESTAMP_NTZ(9),
SALES_TERRITORY_ID STRING,
SALESPERSON STRING,
AM_OR_RSM STRING,
VPS_NAME STRING,
VPGM STRING,
ACM STRING,
CAN_NUMBER STRING,
CAN_NAME STRING,
PRE_PAY_DAYS STRING,
PREPAY_BY_CAN STRING,
CASH_DISCOUNT_FLAG STRING,
PAY_METHOD STRING,
PAY_METHOD_DESC STRING,
PAYMENT_TERMS_CD STRING,
PAYMENT_TERMS_DESC STRING,
DSO NUMBER,
ADP NUMBER,
MIN_DSO NUMBER,
MAX_DSO NUMBER,
PAYMENT_TYPE STRING,
DUE_DATE STRING,
RX_BILL_PLAN_CD STRING,
RX_BILL_PLAN NUMBER,
RX_PROMO_BP STRING,
RX_PROMO_COG NUMBER,
OTC_BILL_PLAN_CD STRING,
OTC_BILL_PLAN NUMBER,
OTC_PROMO_BP STRING,
OTC_PROMO_COG NUMBER,
CUST_DROP_SHIP_IND STRING,
DROP_SHIP_RX_BILL_ NUMBER,
DROP_SHIP_OTC_BILL NUMBER,
SALES_AGREEMENT_TY STRING,
AGREEMENT_EXPIRATION TIMESTAMP_NTZ(9),
MCF_NUM STRING,
AGREEMENT STRING,
ROUTE STRING,
STOP STRING,
TOTAL_DELIVERIES NUMBER,
COGS_DIFF NUMBER,
NEW_RX_COGS NUMBER,
NEW_OTC_COGS NUMBER,
NET_MONTHLY_AVERAG NUMBER(10,2),
DISTRIBUTION_CHANN STRING,
BUS_TYPE_CD STRING,
BUS_TYPE_DESC STRING,
RETURNS_MATRIX STRING,
FUEL_SURCHARGE STRING,
REDS_FEE_PLAN STRING,
FREE_REDS_PER_MONT STRING,
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_QUARTERLY_AUDIT_DATA'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.T_MT_PHS_DMEM(
CUST_ACCT_ID STRING,
LEAD STRING,
LEAD_NAME STRING,
EXPANSION_ENTITY STRING,
ENTITY_TYPE STRING,
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_MT_PHS_DMEM'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true);


-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.T_DMEM_LIST(
CUST_ACCT_ID STRING,
CNTRCT_LEAD_ID STRING,
PRTY_CONT STRING,
MARKUP_CONT NUMBER,
CONT_PREFD STRING,
LEAD_NAME STRING,
LEAD_TYPE STRING,
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_DMEM_LIST'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true);


-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.T_MT_WAC_DMEM(
CUST_ACCT_ID STRING, 
LEAD STRING, 
LEAD_NAME STRING,
EXPANSION_ENTITY  STRING,
ENTITY_TYPE  STRING,
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_MT_WAC_DMEM'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.T_MT_LEAD_LIST(
  CNTRCT_LEAD_ID STRING,
  CNTRCT_LEAD_NAME STRING,
  CNTRCT_LEAD_TYPE STRING,
  _rescued_data STRING
  COMMENT 'Rescued Data',
  ADF_RUN_ID STRING
  COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING
  COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp
  COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING
  COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING
  COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING
  COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME))
  COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME))
  COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_MT_LEAD_LIST'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles' = true
);

-- COMMAND ----------

CREATE TABLE IF NOT EXISTS psas_di_dev.340b_slvr.T_PHS_MEMBERSHIPROSTER_MEMBERS(
 CUST_ACCT_ID STRING,
 CUST_NAME STRING,
 PVP_MEMBER_NAME STRING,
 COVERED_ENTITY_PRIMARY STRING,
 PHARMACY_NAME STRING,
 CONTRACT_PHARMACY STRING,
 CONTRACT_PHARMACY_PRIMARY STRING,
 DEA_FAMILY STRING,
 HOME_DC_ID STRING,
 DEA_NUM STRING,
 HIN_BASE_CD STRING,
 HIN_DEPT_CD STRING,
 HIN_LOCATION_CD STRING,
 HIN_NUM STRING,
 340B_ID STRING,
 PVP_PARTICIPANT_ID STRING,
 PVP_PARTICIPATION_FLAG STRING,
 PVP_EFFECTIVE_DATE DATE, 
 PVP_EXPIRATION_DATE DATE, 
 ATTENTION_NAME_DELY STRING,
 ADDR_LINE_1_DELY STRING,
 ADDR_LINE_2_DELY STRING,
 CITY_NAME_DELY STRING,
 STATE_CD_DELY STRING,
 ZIP_CD_DELY STRING,
 ATTENTION_NAME_INV STRING,
 ADDR_LINE_1_INV STRING,
 ADDR_LINE_2_INV STRING,
 CITY_NAME_INV STRING,
 STATE_CD_INV STRING,
 ZIP_CD_INV STRING,
 CUST_CHAIN_ID STRING,
 CUST_CHAIN_NAME STRING,
 NATIONAL_GROUP_CD STRING,
 NATIONAL_GROUP_NAME STRING,
 NATIONAL_SUB_GROUP_CD STRING,
 NATIONAL_SUB_GROUP_NAME STRING,
 REGION_NUM STRING,
 REGION_NAME STRING,
 DISTRICT_NUM STRING,
 DISTRICT_NAME STRING,
 RX_BILL_PLAN_CD STRING,
 BUSINESS_TYPE_CD STRING,
 DISTRIBUTION_CHANNEL STRING,
 SALES_TERRITORY_ID STRING,
 PRIMARY_CUST_ID STRING,
 THIRD_PARTY_VENDOR STRING,
 SECONDARY_VENDOR STRING,
 OTHER_VENDORS STRING,
 ACCOUNT_CLASSIFICATION STRING,
 ACCOUNT_CLASSIFICATION_DESCRIPTION STRING,
 RECEIVED_DSCSA_AGREEMENT STRING,
 EXTENDED_TO_MPB_YN STRING,
  _rescued_data STRING COMMENT 'Rescued Data',
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pipeline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'Run ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'Job ID of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION 'abfss://catalog@stpsasdi340bdev.dfs.core.windows.net/slvr/T_PHS_MEMBERSHIPROSTER_MEMBERS'
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true);

